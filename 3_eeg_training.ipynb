{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG-Based Gesture Classification using Deep Learning\n",
    "\n",
    "This notebook implements and compares three deep learning approaches for classifying gestures from EEG signals:\n",
    "\n",
    "1. **1D Convolutional Neural Network (CNN)**: Extracts spatial patterns from EEG channel data\n",
    "2. **Long Short-Term Memory (LSTM)**: Captures temporal dependencies in brain signal sequences  \n",
    "3. **Hybrid CNN-LSTM Model**: Combines CNN's spatial feature extraction with LSTM's temporal modeling\n",
    "\n",
    "EEG signals measure electrical activity in the brain, allowing for gesture recognition through machine learning. This has applications in brain-computer interfaces, neurofeedback, and assistive technologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Tuple, List, Dict\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset from a CSV file.\n",
    "df = pd.read_csv(\"data/processed/EEG-data.csv\")\n",
    "\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# Set device for PyTorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def print_color(text: str, color: str) -> None:\n",
    "    \"\"\"\n",
    "    Prints text in specified ANSI color for better readability.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be printed\n",
    "        color (str): Color name ('red', 'green', 'yellow', 'blue', 'magenta')\n",
    "    \"\"\"\n",
    "    colors = {\n",
    "        \"red\": \"\\033[91m\",\n",
    "        \"green\": \"\\033[92m\",\n",
    "        \"yellow\": \"\\033[93m\",\n",
    "        \"blue\": \"\\033[94m\",\n",
    "        \"magenta\": \"\\033[95m\"\n",
    "    }\n",
    "    print(f\"{colors.get(color, '')}{text}\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adjust gesture labels to be zero-indexed\n",
    "df['gesture'] = df['gesture'] - 1\n",
    "\n",
    "# Count number of unique gestures\n",
    "num_classes = df['gesture'].nunique()\n",
    "\n",
    "# Display initial data and dataset structure\n",
    "print_color(\"Head of DataFrame:\", \"green\")\n",
    "print(df.head())\n",
    "print_color(\"Shape of DataFrame:\", \"green\")\n",
    "print(df.shape)\n",
    "\n",
    "# Check and display any null values in the dataset\n",
    "null_count = df.isnull().sum()\n",
    "print_color(\"Null values in each column:\", \"yellow\")\n",
    "print(null_count)\n",
    "\n",
    "# List and display unique gestures and subjects\n",
    "print_color(\"Unique gestures (after adjustment to 0-index):\", \"blue\")\n",
    "print(sorted(df[\"gesture\"].unique()))\n",
    "print_color(\"Unique subjects:\", \"blue\")\n",
    "print(sorted(df[\"subject\"].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Windowing Setup\n",
    "# Set window size and step size for slicing the data\n",
    "WINDOW_SIZE = 100  # Number of samples per window\n",
    "STEP_SIZE = 50     # Interval at which new windows are created\n",
    "\n",
    "# Initialize lists to store windowed data and corresponding labels\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Group the data by gesture, extracting features for each gesture\n",
    "for gesture_id in sorted(df[\"gesture\"].unique()):\n",
    "    gesture_df = df[df[\"gesture\"] == gesture_id]\n",
    "    gesture_data = gesture_df[\n",
    "        [\"Channel_1\", \"Channel_2\", \"Channel_3\", \"Channel_4\",\n",
    "         \"Channel_5\", \"Channel_6\", \"Channel_7\", \"Channel_8\"]\n",
    "    ].values  # Extract channel data as numpy array\n",
    "\n",
    "    # Generate overlapping windows of data\n",
    "    for start_idx in range(0, len(gesture_data) - WINDOW_SIZE + 1, STEP_SIZE):\n",
    "        window_data = gesture_data[start_idx:start_idx + WINDOW_SIZE]\n",
    "        X_list.append(window_data)\n",
    "        y_list.append(gesture_id)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_array = np.array(X_list)\n",
    "y_array = np.array(y_list)\n",
    "\n",
    "\n",
    "# Display shapes of the prepared datasets\n",
    "print_color(\"Shape of X_array:\", \"red\")\n",
    "print(X_array.shape)\n",
    "print_color(\"Shape of y_array:\", \"red\")\n",
    "print(y_array.shape)\n",
    "\n",
    "# Print statistics about the data\n",
    "print_color(\"Data statistics in X_array:\", \"green\")\n",
    "print(\"Mean:\", np.mean(X_array, axis=(0, 1)))\n",
    "print(\"Standard Deviation:\", np.std(X_array, axis=(0, 1)))\n",
    "print(\"Max value:\", np.max(X_array))\n",
    "print(\"Min value:\", np.min(X_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data\n",
    "X_mean = np.mean(X_array)\n",
    "X_std = np.std(X_array)\n",
    "X_array = (X_array - X_mean) / X_std\n",
    "\n",
    "# Convert to PyTorch tensors and move to device\n",
    "X_tensor = torch.FloatTensor(X_array).to(device)\n",
    "y_tensor = torch.LongTensor(y_array).to(device)\n",
    "\n",
    "# Print statistics about the tensor data\n",
    "print_color(\"Shape of X_tensor:\", \"red\")\n",
    "print(X_tensor.shape)\n",
    "print_color(\"Shape of y_tensor:\", \"red\")\n",
    "print(y_tensor.shape)\n",
    "print_color(\"Data statistics in X_tensor:\", \"green\")\n",
    "print(f\"Mean: {X_tensor.mean().item():.4f}\")\n",
    "print(f\"Standard Deviation: {X_tensor.std().item():.4f}\")\n",
    "print(f\"Max value: {X_tensor.max().item():.4f}\")\n",
    "print(f\"Min value: {X_tensor.min().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data into train, validation, test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tensor, y_tensor, test_size=0.2, random_state=RANDOM_SEED, stratify=y_tensor.cpu()\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=RANDOM_SEED, stratify=y_train.cpu()\n",
    ")\n",
    "\n",
    "print_color(f\"Train set: {X_train.shape[0]} samples\", \"green\")\n",
    "print_color(f\"Validation set: {X_val.shape[0]} samples\", \"green\")\n",
    "print_color(f\"Test set: {X_test.shape[0]} samples\", \"green\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1D(nn.Module):\n",
    "    def __init__(self, win_size: int, num_channels: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv1d(num_channels, 128, kernel_size=5, padding=2),  # Increased filters\n",
    "            nn.BatchNorm1d(128),  # Added batch norm\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            \n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),  # Added extra layer\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            \n",
    "            nn.Conv1d(256, 512, kernel_size=3, padding=1),  # Deeper architecture\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),  # Better than fixed pooling\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),  # Increased dropout\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Permute to (batch_size, channels, time_steps)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, win_size, num_channels, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size=num_channels, hidden_size=64, batch_first=True, bidirectional=False)\n",
    "        self.drop1 = nn.Dropout(0.2)  # Apply dropout after first LSTM\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=64, batch_first=True, bidirectional=False)\n",
    "        self.drop2 = nn.Dropout(0.2)  # Apply dropout after second LSTM\n",
    "\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.drop_fc = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.drop1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.drop2(x)\n",
    "\n",
    "        x = x[:, -1, :]  # Take only the last time step output\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop_fc(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNNLSTMModel(nn.Module):\n",
    "    def __init__(self, win_size, num_channels, num_classes):\n",
    "        super(CNNLSTMModel, self).__init__()\n",
    "       \n",
    "        # --- CNN Block ---\n",
    "        self.cnn_block = nn.Sequential(\n",
    "            nn.Conv1d(num_channels, 128, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.2),\n",
    "           \n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "       \n",
    "        # --- Attention Layer ---\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv1d(256, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "       \n",
    "        # --- LSTM Block (Fixed Dropout) ---\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            input_size=256,\n",
    "            hidden_size=128,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0  # Fixed: Set to 0 for a single-layer LSTM\n",
    "        )\n",
    "       \n",
    "        self.lstm2 = nn.LSTM(\n",
    "            input_size=256,  # 128*2 due to bidirectional\n",
    "            hidden_size=128,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0  # Fixed: Set to 0 for a single-layer LSTM\n",
    "        )\n",
    "       \n",
    "        # --- Fully Connected Layers ---\n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Linear(256, 512),  # 128*2 due to bidirectional\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "       \n",
    "    def forward(self, x):\n",
    "        # Reshape input for CNN: (batch_size, channels, time_steps)\n",
    "        x = x.permute(0, 2, 1)\n",
    "           \n",
    "        # CNN feature extraction\n",
    "        cnn_features = self.cnn_block(x)\n",
    "       \n",
    "        # Apply attention to CNN features\n",
    "        attention_weights = self.attention(cnn_features)\n",
    "        attended_features = cnn_features * attention_weights\n",
    "       \n",
    "        # Reshape for LSTM: (batch, time, features)\n",
    "        lstm_input = attended_features.permute(0, 2, 1)\n",
    "       \n",
    "        # LSTM processing\n",
    "        lstm_out1, _ = self.lstm1(lstm_input)\n",
    "        lstm_out2, _ = self.lstm2(lstm_out1)\n",
    "       \n",
    "        # Global context representation (max + avg pooling)\n",
    "        max_pool = torch.max(lstm_out2, dim=1)[0]\n",
    "        avg_pool = torch.mean(lstm_out2, dim=1)\n",
    "        combined_features = max_pool + avg_pool\n",
    "       \n",
    "        # Final classification\n",
    "        output = self.fc_block(combined_features)\n",
    "       \n",
    "        return output\n",
    "   \n",
    "    def initialize_weights(self):\n",
    "        \"\"\"Initialize model weights for better convergence\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training and Evaluation Functions\n",
    "def train_model(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader,\n",
    "               criterion: nn.Module, optimizer: torch.optim.Optimizer, \n",
    "               device: torch.device, epochs: int = 10) -> Tuple[List[float], List[float], List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Train a model using the provided data loader.\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model\n",
    "        train_loader: DataLoader for training data\n",
    "        val_loader: DataLoader for validation data\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer for updating model weights\n",
    "        device: Device to perform computations on (CPU/GPU)\n",
    "        epochs: Number of training epochs\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train_losses, val_losses, train_accs, val_accs)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        for inputs, targets in progress_bar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': running_loss/total, \n",
    "                'acc': 100.*correct/total\n",
    "            })\n",
    "        \n",
    "        # Training epoch statistics\n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = 100. * correct / total\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accs.append(epoch_train_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # Validation epoch statistics\n",
    "        epoch_val_loss = val_running_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = 100. * val_correct / val_total\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accs.append(epoch_val_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%, Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.2f}%')\n",
    "    \n",
    "    return train_losses, val_losses, train_accs, val_accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "# Loss function with class weights if needed\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create directory for models\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "all_metrics = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train CNN model\n",
    "print_color(\"\\nTraining CNN Model...\", \"magenta\")\n",
    "cnn_model = CNN1D(win_size=100, num_channels=8, num_classes=num_classes).to(device)\n",
    "cnn_optimizer = optim.Adam(cnn_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "start_time = time.time()\n",
    "cnn_train_losses, cnn_val_losses, cnn_train_accs, cnn_val_accs = train_model(\n",
    "        cnn_model, train_loader, val_loader, criterion, cnn_optimizer, device, EPOCHS\n",
    "    )\n",
    "cnn_train_time = time.time() - start_time\n",
    "\n",
    "all_metrics['CNN'] = {\n",
    "      'train_loss': cnn_train_losses,\n",
    "      'val_loss': cnn_val_losses,\n",
    "      'train_acc': cnn_train_accs,\n",
    "      'val_acc': cnn_val_accs\n",
    "  }\n",
    "\n",
    "print(f\"CNN training completed in {cnn_train_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train LSTM model\n",
    "print_color(\"\\nTraining LSTM Model...\", \"magenta\")\n",
    "lstm_model = LSTMModel(win_size=100, num_channels=8, num_classes=num_classes).to(device)\n",
    "lstm_optimizer = optim.Adam(lstm_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "start_time = time.time()\n",
    "lstm_train_losses, lstm_val_losses, lstm_train_accs, lstm_val_accs = train_model(\n",
    "       lstm_model, train_loader, val_loader, criterion, lstm_optimizer, device, EPOCHS\n",
    "   )\n",
    "lstm_train_time = time.time() - start_time\n",
    "\n",
    "\n",
    "all_metrics['LSTM'] = {\n",
    "    'train_loss': lstm_train_losses,\n",
    "    'val_loss': lstm_val_losses,\n",
    "    'train_acc': lstm_train_accs,\n",
    "    'val_acc': lstm_val_accs\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"LSTM training completed in {lstm_train_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train CNN-LSTM hybrid model\n",
    "print_color(\"\\nTraining CNN-LSTM Hybrid Model...\", \"magenta\")\n",
    "cnn_lstm_model = CNNLSTMModel(win_size=100, num_channels=8, num_classes=num_classes).to(device)\n",
    "cnn_lstm_model.initialize_weights()\n",
    "cnn_lstm_optimizer = optim.Adam(cnn_lstm_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "start_time = time.time()\n",
    "cnn_lstm_train_losses, cnn_lstm_val_losses, cnn_lstm_train_accs, cnn_lstm_val_accs = train_model(\n",
    "    cnn_lstm_model, train_loader, val_loader, criterion, cnn_lstm_optimizer, device, EPOCHS\n",
    ")\n",
    "cnn_lstm_train_time = time.time() - start_time\n",
    "\n",
    "\n",
    "all_metrics['CNN-LSTM'] = {\n",
    "    'train_loss': cnn_lstm_train_losses,\n",
    "    'val_loss': cnn_lstm_val_losses,\n",
    "    'train_acc': cnn_lstm_train_accs,\n",
    "    'val_acc': cnn_lstm_val_accs\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"CNN-LSTM training completed in {cnn_lstm_train_time:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_model_comparison(metrics_dict: Dict[str, Dict[str, List[float]]]) -> None:\n",
    "    \"\"\"\n",
    "    Plot comparison of training and validation metrics for multiple models.\n",
    "\n",
    "    Args:\n",
    "        metrics_dict: Dictionary with model names as keys and dictionaries of metrics as values\n",
    "                      The inner dictionaries should have keys 'train_loss', 'val_loss', 'train_acc', 'val_acc'\n",
    "    \"\"\"\n",
    "    \n",
    "    save_path = 'results/3_eeg_model_comparison.png'\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))  # 2 rows, 2 columns\n",
    "    \n",
    "    # Colors for different models\n",
    "    colors = {'CNN': 'blue', 'LSTM': 'red', 'CNN-LSTM': 'green'}\n",
    "    \n",
    "    # Plot Training Accuracy (Top Left)\n",
    "    for model_name, metrics in metrics_dict.items():\n",
    "        axes[0, 0].plot(metrics['train_acc'], \"-o\", color=colors[model_name], label=f\"{model_name} Train\")\n",
    "    axes[0, 0].set_title('Training Accuracy', fontsize=14)\n",
    "    axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    axes[0, 0].legend(loc='lower right', fontsize=10)\n",
    "    axes[0, 0].grid(True)\n",
    "\n",
    "    # Plot Validation Accuracy (Top Right)\n",
    "    for model_name, metrics in metrics_dict.items():\n",
    "        axes[0, 1].plot(metrics['val_acc'], \"--o\", color=colors[model_name], label=f\"{model_name} Val\")\n",
    "    axes[0, 1].set_title('Validation Accuracy', fontsize=14)\n",
    "    axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    axes[0, 1].legend(loc='lower right', fontsize=10)\n",
    "    axes[0, 1].grid(True)\n",
    "\n",
    "    # Plot Training Loss (Bottom Left)\n",
    "    for model_name, metrics in metrics_dict.items():\n",
    "        axes[1, 0].plot(metrics['train_loss'], \"-o\", color=colors[model_name], label=f\"{model_name} Train\")\n",
    "    axes[1, 0].set_title('Training Loss', fontsize=14)\n",
    "    axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[1, 0].legend(loc='upper right', fontsize=10)\n",
    "    axes[1, 0].grid(True)\n",
    "\n",
    "    # Plot Validation Loss (Bottom Right)\n",
    "    for model_name, metrics in metrics_dict.items():\n",
    "        axes[1, 1].plot(metrics['val_loss'], \"--o\", color=colors[model_name], label=f\"{model_name} Val\")\n",
    "    axes[1, 1].set_title('Validation Loss', fontsize=14)\n",
    "    axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Loss', fontsize=12)\n",
    "    axes[1, 1].legend(loc='upper right', fontsize=10)\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    fig.suptitle(\"EEG Dataset - Training Results Comparison\", fontsize=20, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of all models\n",
    "print_color(\"\\nPlotting model comparison...\", \"blue\")\n",
    "plot_model_comparison(all_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This comparative analysis demonstrates the effectiveness of different deep learning architectures for EEG-based gesture recognition. The results show that the hybrid CNN-LSTM model generally performs best by leveraging both spatial and temporal features from the EEG signals.\n",
    "\n",
    "Future work could explore:\n",
    "- Transfer learning between subjects\n",
    "- More sophisticated attention mechanisms\n",
    "- Hyperparameter optimization\n",
    "- Real-time implementation for brain-computer interfaces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
