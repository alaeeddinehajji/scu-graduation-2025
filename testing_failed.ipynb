{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.amp import autocast, GradScaler\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "import random\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set memory optimization flags and reproducibility\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.empty_cache()\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, emg_data, eeg_data, labels):\n",
    "        self.emg_data = torch.FloatTensor(emg_data)\n",
    "        self.eeg_data = torch.FloatTensor(eeg_data)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.emg_data[idx], self.eeg_data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultimodalCNN(\n",
      "  (emg_encoder): EMGEncoder(\n",
      "    (model): Sequential(\n",
      "      (0): Conv1d(8, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU()\n",
      "      (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (8): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (9): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): ReLU()\n",
      "      (11): AdaptiveAvgPool1d(output_size=1)\n",
      "    )\n",
      "  )\n",
      "  (eeg_encoder): EEGEncoder(\n",
      "    (model): Sequential(\n",
      "      (0): Conv1d(6, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU()\n",
      "      (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (8): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (9): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): ReLU()\n",
      "      (11): AdaptiveAvgPool1d(output_size=1)\n",
      "    )\n",
      "  )\n",
      "  (fusion): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Linear(in_features=256, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Update the EMGEncoder and EEGEncoder classes with residual connections and dropout\n",
    "class EMGEncoder(nn.Module):\n",
    "    def __init__(self, num_channels, hidden_dim):\n",
    "        super(EMGEncoder, self).__init__()\n",
    "        self.input_conv = nn.Sequential(\n",
    "            nn.Conv1d(num_channels, hidden_dim, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # Residual blocks\n",
    "        self.res_blocks = nn.ModuleList([\n",
    "            ResidualBlock(hidden_dim, hidden_dim * 2),\n",
    "            ResidualBlock(hidden_dim * 2, hidden_dim * 4)\n",
    "        ])\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # [batch, channels, timesteps]\n",
    "        x = self.input_conv(x)\n",
    "        \n",
    "        # Apply residual blocks\n",
    "        for block in self.res_blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.global_pool(x)\n",
    "        return x.view(x.shape[0], -1)  # Flatten\n",
    "\n",
    "class EEGEncoder(nn.Module):\n",
    "    def __init__(self, num_channels, hidden_dim):\n",
    "        super(EEGEncoder, self).__init__()\n",
    "        self.input_conv = nn.Sequential(\n",
    "            nn.Conv1d(num_channels, hidden_dim, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # Residual blocks\n",
    "        self.res_blocks = nn.ModuleList([\n",
    "            ResidualBlock(hidden_dim, hidden_dim * 2),\n",
    "            ResidualBlock(hidden_dim * 2, hidden_dim * 4)\n",
    "        ])\n",
    "        \n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.input_conv(x)\n",
    "        \n",
    "        for block in self.res_blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.global_pool(x)\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "# Add ResidualBlock class\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x += self.shortcut(residual)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "# Update MultimodalCNN with attention and improved fusion\n",
    "class MultimodalCNN(nn.Module):\n",
    "    def __init__(self, emg_channels, eeg_channels, hidden_dim, num_classes):\n",
    "        super(MultimodalCNN, self).__init__()\n",
    "        \n",
    "        # Print initialization parameters for debugging\n",
    "        print(f\"Initializing MultimodalCNN with:\")\n",
    "        print(f\"EMG channels: {emg_channels}\")\n",
    "        print(f\"EEG channels: {eeg_channels}\")\n",
    "        print(f\"Hidden dim: {hidden_dim}\")\n",
    "        print(f\"Num classes: {num_classes}\")\n",
    "        \n",
    "        self.emg_encoder = EMGEncoder(emg_channels, hidden_dim)\n",
    "        self.eeg_encoder = EEGEncoder(eeg_channels, hidden_dim)\n",
    "        \n",
    "        feature_dim = hidden_dim * 4 * 2  # Both encoders output hidden_dim * 4\n",
    "        \n",
    "        # Cross-modal attention\n",
    "        self.attention = CrossModalAttention(hidden_dim * 4)\n",
    "        \n",
    "        # Improved fusion network with skip connections\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(feature_dim, hidden_dim * 4),\n",
    "            nn.LayerNorm(hidden_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            ResidualLinear(hidden_dim * 4, hidden_dim * 2),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            ResidualLinear(hidden_dim * 2, hidden_dim),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, emg, eeg):\n",
    "        emg_features = self.emg_encoder(emg)\n",
    "        eeg_features = self.eeg_encoder(eeg)\n",
    "        \n",
    "        # Apply cross-modal attention\n",
    "        emg_attended, eeg_attended = self.attention(emg_features, eeg_features)\n",
    "        \n",
    "        # Concatenate attended features\n",
    "        combined = torch.cat((emg_attended, eeg_attended), dim=1)\n",
    "        return self.fusion(combined)\n",
    "\n",
    "# Add CrossModalAttention class\n",
    "class CrossModalAttention(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(CrossModalAttention, self).__init__()\n",
    "        self.query_transform = nn.Linear(feature_dim, feature_dim)\n",
    "        self.key_transform = nn.Linear(feature_dim, feature_dim)\n",
    "        self.value_transform = nn.Linear(feature_dim, feature_dim)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([feature_dim])).to(device)\n",
    "        \n",
    "    def forward(self, emg_features, eeg_features):\n",
    "        # EMG attending to EEG\n",
    "        Q_emg = self.query_transform(emg_features)\n",
    "        K_eeg = self.key_transform(eeg_features)\n",
    "        V_eeg = self.value_transform(eeg_features)\n",
    "        \n",
    "        attention_weights = torch.matmul(Q_emg, K_eeg.transpose(-2, -1)) / self.scale\n",
    "        attention_weights = F.softmax(attention_weights, dim=-1)\n",
    "        emg_attended = torch.matmul(attention_weights, V_eeg)\n",
    "        \n",
    "        # EEG attending to EMG\n",
    "        Q_eeg = self.query_transform(eeg_features)\n",
    "        K_emg = self.key_transform(emg_features)\n",
    "        V_emg = self.value_transform(emg_features)\n",
    "        \n",
    "        attention_weights = torch.matmul(Q_eeg, K_emg.transpose(-2, -1)) / self.scale\n",
    "        attention_weights = F.softmax(attention_weights, dim=-1)\n",
    "        eeg_attended = torch.matmul(attention_weights, V_emg)\n",
    "        \n",
    "        return emg_attended, eeg_attended\n",
    "\n",
    "# Add ResidualLinear class for the fusion network\n",
    "class ResidualLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(ResidualLinear, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features, out_features)\n",
    "        self.ln1 = nn.LayerNorm(out_features)\n",
    "        self.linear2 = nn.Linear(out_features, out_features)\n",
    "        self.ln2 = nn.LayerNorm(out_features)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_features != out_features:\n",
    "            self.shortcut = nn.Linear(in_features, out_features)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.ln1(self.linear1(x)))\n",
    "        x = self.ln2(self.linear2(x))\n",
    "        x += self.shortcut(residual)\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MultimodalCNN(emg_channels=8, eeg_channels=6, hidden_dim=128, num_classes=6).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation function defined to add random noise during training\n"
     ]
    }
   ],
   "source": [
    "# Add noise to data for augmentation\n",
    "def add_noise(data, noise_factor=0.05):\n",
    "    noise = torch.randn(data.shape).to(data.device) * noise_factor * torch.std(data)\n",
    "    return data + noise\n",
    "\n",
    "print(\"Data augmentation function defined to add random noise during training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading and processing function defined with windowing and standardization\n"
     ]
    }
   ],
   "source": [
    "def load_and_process_data(emg_path, eeg_path, window_size=50, stride=25):\n",
    "    print(\"Loading data...\")\n",
    "    \n",
    "    # Load data\n",
    "    emg_data = pd.read_csv(emg_path)\n",
    "    eeg_data = pd.read_csv(eeg_path)\n",
    "    \n",
    "    # Extract features and labels\n",
    "    emg_features = emg_data.iloc[:, :8].values  # Make sure we're getting exactly 8 channels\n",
    "    eeg_features = eeg_data.iloc[:, :8].values  # Make sure we're getting exactly 8 channels\n",
    "    \n",
    "    print(f\"EMG features shape: {emg_features.shape}\")\n",
    "    print(f\"EEG features shape: {eeg_features.shape}\")\n",
    "    \n",
    "    # Standardize the features\n",
    "    print(\"Normalizing data...\")\n",
    "    emg_scaler = StandardScaler()\n",
    "    eeg_scaler = StandardScaler()\n",
    "    \n",
    "    emg_features = emg_scaler.fit_transform(emg_features)\n",
    "    eeg_features = eeg_scaler.fit_transform(eeg_features)\n",
    "    \n",
    "    # Create windowed data\n",
    "    emg_windows = []\n",
    "    eeg_windows = []\n",
    "    window_labels = []\n",
    "    sample_ids = []  # Track sample IDs for stratified splits\n",
    "    \n",
    "    # Find common samples between EMG and EEG data\n",
    "    emg_samples = set(tuple(x) for x in emg_data[['subject', 'repetition', 'gesture']].drop_duplicates().values)\n",
    "    eeg_samples = set(tuple(x) for x in eeg_data[['subject', 'repetition', 'gesture']].drop_duplicates().values)\n",
    "    common_samples = emg_samples.intersection(eeg_samples)\n",
    "    \n",
    "    print(f\"Found {len(common_samples)} common samples between EMG and EEG data.\")\n",
    "    \n",
    "    for sample in common_samples:\n",
    "        subject, repetition, gesture = sample\n",
    "        \n",
    "        # Get data for this sample\n",
    "        emg_sample = emg_data[(emg_data['subject'] == subject) & \n",
    "                             (emg_data['repetition'] == repetition) & \n",
    "                             (emg_data['gesture'] == gesture)]\n",
    "        \n",
    "        eeg_sample = eeg_data[(eeg_data['subject'] == subject) & \n",
    "                             (eeg_data['repetition'] == repetition) & \n",
    "                             (eeg_data['gesture'] == gesture)]\n",
    "        \n",
    "        # Make sure both samples have data\n",
    "        if len(emg_sample) == 0 or len(eeg_sample) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Extract features\n",
    "        emg_sample_features = emg_sample.iloc[:, :8].values\n",
    "        eeg_sample_features = eeg_sample.iloc[:, :8].values\n",
    "        \n",
    "        # Standardize using pre-fitted scalers\n",
    "        emg_sample_features = emg_scaler.transform(emg_sample_features)\n",
    "        eeg_sample_features = eeg_scaler.transform(eeg_sample_features)\n",
    "        \n",
    "        # Handle different lengths by using the shorter one\n",
    "        min_length = min(len(emg_sample_features), len(eeg_sample_features))\n",
    "        if min_length <= window_size:\n",
    "            continue  # Skip if sample is too short\n",
    "            \n",
    "        emg_sample_features = emg_sample_features[:min_length]\n",
    "        eeg_sample_features = eeg_sample_features[:min_length]\n",
    "        \n",
    "        # Create windows\n",
    "        for i in range(0, min_length - window_size, stride):\n",
    "            emg_windows.append(emg_sample_features[i:i+window_size])\n",
    "            eeg_windows.append(eeg_sample_features[i:i+window_size])\n",
    "            window_labels.append(gesture - 1)  # 0-indexed labels\n",
    "            sample_ids.append(f\"{subject}_{repetition}_{gesture}\")  # Track which sample this comes from\n",
    "    \n",
    "    if len(emg_windows) == 0:\n",
    "        raise ValueError(\"No valid windows could be created. Check your data alignment.\")\n",
    "    \n",
    "    print(f\"Created {len(emg_windows)} windows from {len(common_samples)} samples.\")\n",
    "    \n",
    "    return np.array(emg_windows), np.array(eeg_windows), np.array(window_labels), np.array(sample_ids)\n",
    "\n",
    "print(\"Data loading and processing function defined with windowing and standardization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training function updated with gradient clipping and learning rate warmup.\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
    "                num_epochs=10, clip_grad=1.0, warmup_epochs=3, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Training function with improved features including warmup, early stopping, and gradient clipping\n",
    "    \"\"\"\n",
    "   \n",
    "    # Increase early stopping patience\n",
    "    early_stopping_patience = 15  # Changed from 5 to 15\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    min_delta = 0.001  # Minimum change in validation loss to be considered as improvement\n",
    "    \n",
    "    # Add learning rate warmup\n",
    "    warmup_factor = 1.0 / warmup_epochs\n",
    "    \n",
    "    # Initialize gradient scaler for mixed precision training\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Add weighted cross entropy loss to handle class imbalance\n",
    "    class_counts = torch.bincount(torch.tensor([label for _, _, label in train_loader.dataset]))\n",
    "    weights = 1.0 / class_counts.float()\n",
    "    weights = weights / weights.sum()\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights.to(device), label_smoothing=0.1)\n",
    "\n",
    "\n",
    "    # Add early stopping\n",
    "    early_stopping_patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Keep track of metrics\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [], 'train_f1': [],\n",
    "        'val_loss': [], 'val_acc': [], 'val_f1': [],\n",
    "        'learning_rates': []\n",
    "    }\n",
    "\n",
    "    # Store initial learning rate\n",
    "    initial_lr = learning_rate\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Modified learning rate warmup\n",
    "        if epoch < warmup_epochs:\n",
    "            lr = learning_rate * ((epoch + 1) / warmup_epochs)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "        \n",
    "        # Training phase with gradient accumulation\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        # Add progress bar\n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        # Add gradient accumulation steps\n",
    "        accumulation_steps = 2  # Accumulate gradients every 2 steps\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for i, (emg_inputs, eeg_inputs, labels) in enumerate(pbar):\n",
    "            # Move data to device\n",
    "            emg_inputs = emg_inputs.to(device)\n",
    "            eeg_inputs = eeg_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Data augmentation (add noise) in training only\n",
    "            if random.random() < 0.5:  # 50% chance to apply noise\n",
    "                emg_inputs = add_noise(emg_inputs, noise_factor=0.03)\n",
    "                eeg_inputs = add_noise(eeg_inputs, noise_factor=0.03)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                outputs = model(emg_inputs, eeg_inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize with gradient scaling\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Store predictions and labels for F1 score calculation\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'lr': f'{optimizer.param_groups[0][\"lr\"]:.6f}'\n",
    "            })\n",
    "            \n",
    "            # Free up memory\n",
    "            if i % 10 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * np.mean(np.array(all_preds) == np.array(all_targets))\n",
    "        train_f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss, val_acc, val_f1 = validate_model(model, val_loader, criterion)\n",
    "        \n",
    "        # Store metrics\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_f1'].append(train_f1)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        history['learning_rates'].append(optimizer.param_groups[0]['lr'])\n",
    "          \n",
    "        # Modify the early stopping check\n",
    "        if val_loss < (best_val_loss - min_delta):\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                'val_loss': val_loss,\n",
    "                'val_acc': val_acc,\n",
    "                'val_f1': val_f1,\n",
    "                'history': history\n",
    "            }, 'best_model_checkpoint.pth')\n",
    "            print(f'Saved new best model with validation loss: {val_loss:.4f}')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "                print(f'Best validation loss: {best_val_loss:.4f}')\n",
    "                break\n",
    "            \n",
    "        # Update learning rate (except during warmup)\n",
    "        if epoch >= warmup_epochs and scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Train F1: {train_f1:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, Val F1: {val_f1:.4f}')\n",
    "        print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        print('-' * 80)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    \"\"\"\n",
    "    Enhanced validation function that returns loss, accuracy and F1 score\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for emg_inputs, eeg_inputs, labels in val_loader:\n",
    "            emg_inputs = emg_inputs.to(device)\n",
    "            eeg_inputs = eeg_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            with autocast(device_type='cuda', dtype=torch.float16):\n",
    "                outputs = model(emg_inputs, eeg_inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "    \n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_acc = 100 * np.mean(np.array(all_preds) == np.array(all_targets))\n",
    "    val_f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "    \n",
    "    return val_loss, val_acc, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation function defined with comprehensive metrics calculation\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate on test set\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for emg_inputs, eeg_inputs, labels in test_loader:\n",
    "            # Move data to device\n",
    "            emg_inputs, eeg_inputs, labels = emg_inputs.to(device), eeg_inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(emg_inputs, eeg_inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Store predictions and labels\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = 100 * np.mean(np.array(all_preds) == np.array(all_targets))\n",
    "    f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "    precision = precision_score(all_targets, all_preds, average='weighted')\n",
    "    recall = recall_score(all_targets, all_preds, average='weighted')\n",
    "    conf_matrix = confusion_matrix(all_targets, all_preds)\n",
    "    \n",
    "    print(\"Test Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "print(\"Model evaluation function defined with comprehensive metrics calculation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional visualization and analysis functions defined\n"
     ]
    }
   ],
   "source": [
    "def visualize_model_predictions(model, test_loader, num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualize model predictions on random samples from the test set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of data\n",
    "    emg_samples, eeg_samples, labels = next(iter(test_loader))\n",
    "    \n",
    "    # Select random indices\n",
    "    indices = np.random.choice(len(emg_samples), min(num_samples, len(emg_samples)), replace=False)\n",
    "    \n",
    "    fig, axs = plt.subplots(num_samples, 2, figsize=(15, 4*num_samples))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        # Get the sample\n",
    "        emg_sample = emg_samples[idx].unsqueeze(0).to(device)\n",
    "        eeg_sample = eeg_samples[idx].unsqueeze(0).to(device)\n",
    "        true_label = labels[idx].item()\n",
    "        \n",
    "        # Get model prediction\n",
    "        with torch.no_grad():\n",
    "            output = model(emg_sample, eeg_sample)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            predicted_label = predicted.item()\n",
    "        \n",
    "        # Plot EMG data\n",
    "        axs[i, 0].plot(emg_sample.cpu().numpy()[0].T)\n",
    "        axs[i, 0].set_title(f'EMG Data: True={true_label}, Pred={predicted_label}')\n",
    "        axs[i, 0].set_xlabel('Time Steps')\n",
    "        axs[i, 0].set_ylabel('Amplitude')\n",
    "        \n",
    "        # Plot EEG data\n",
    "        axs[i, 1].plot(eeg_sample.cpu().numpy()[0].T)\n",
    "        axs[i, 1].set_title(f'EEG Data: True={true_label}, Pred={predicted_label}')\n",
    "        axs[i, 1].set_xlabel('Time Steps')\n",
    "        axs[i, 1].set_ylabel('Amplitude')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sample_predictions.png')\n",
    "    plt.close()\n",
    "    print(\"Visualization saved to 'sample_predictions.png'\")\n",
    "\n",
    "def analyze_feature_importance(model, test_loader):\n",
    "    \"\"\"\n",
    "    Analyze which channels contribute most to model predictions using feature occlusion\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Baseline performance\n",
    "    baseline_results = evaluate_model(model, test_loader)\n",
    "    baseline_accuracy = baseline_results['accuracy']\n",
    "    \n",
    "    emg_channels = 8\n",
    "    eeg_channels = 8\n",
    "    \n",
    "    # Results containers\n",
    "    emg_importance = []\n",
    "    eeg_importance = []\n",
    "    \n",
    "    # Test EMG channel importance\n",
    "    for channel in range(emg_channels):\n",
    "        # Create a modified dataloader with one channel occluded\n",
    "        test_dataset_modified = []\n",
    "        for emg_batch, eeg_batch, labels in test_loader:\n",
    "            emg_batch_mod = emg_batch.clone()\n",
    "            emg_batch_mod[:, :, channel] = 0  # Zero out the channel\n",
    "            test_dataset_modified.append((emg_batch_mod, eeg_batch, labels))\n",
    "        \n",
    "        # Evaluate with this channel occluded\n",
    "        accuracy_drop = 0\n",
    "        total_batches = 0\n",
    "        \n",
    "        for emg_inputs, eeg_inputs, labels in test_dataset_modified:\n",
    "            emg_inputs, eeg_inputs, labels = emg_inputs.to(device), eeg_inputs.to(device), labels.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(emg_inputs, eeg_inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                correct = (predicted == labels).sum().item()\n",
    "                accuracy = 100 * correct / len(labels)\n",
    "                \n",
    "                accuracy_drop += (baseline_accuracy - accuracy)\n",
    "                total_batches += 1\n",
    "        \n",
    "        # Average drop across batches\n",
    "        avg_drop = accuracy_drop / total_batches if total_batches > 0 else 0\n",
    "        emg_importance.append(avg_drop)\n",
    "    \n",
    "    # Test EEG channel importance\n",
    "    for channel in range(eeg_channels):\n",
    "        # Create a modified dataloader with one channel occluded\n",
    "        test_dataset_modified = []\n",
    "        for emg_batch, eeg_batch, labels in test_loader:\n",
    "            eeg_batch_mod = eeg_batch.clone()\n",
    "            eeg_batch_mod[:, :, channel] = 0  # Zero out the channel\n",
    "            test_dataset_modified.append((emg_batch, eeg_batch_mod, labels))\n",
    "        \n",
    "        # Evaluate with this channel occluded\n",
    "        accuracy_drop = 0\n",
    "        total_batches = 0\n",
    "        \n",
    "        for emg_inputs, eeg_inputs, labels in test_dataset_modified:\n",
    "            emg_inputs, eeg_inputs, labels = emg_inputs.to(device), eeg_inputs.to(device), labels.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(emg_inputs, eeg_inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                correct = (predicted == labels).sum().item()\n",
    "                accuracy = 100 * correct / len(labels)\n",
    "                \n",
    "                accuracy_drop += (baseline_accuracy - accuracy)\n",
    "                total_batches += 1\n",
    "        \n",
    "        # Average drop across batches\n",
    "        avg_drop = accuracy_drop / total_batches if total_batches > 0 else 0\n",
    "        eeg_importance.append(avg_drop)\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(range(emg_channels), emg_importance)\n",
    "    plt.title('EMG Channel Importance')\n",
    "    plt.xlabel('Channel')\n",
    "    plt.ylabel('Accuracy Drop (%)')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(range(eeg_channels), eeg_importance)\n",
    "    plt.title('EEG Channel Importance')\n",
    "    plt.xlabel('Channel')\n",
    "    plt.ylabel('Accuracy Drop (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('channel_importance.png')\n",
    "    plt.close()\n",
    "    print(\"Feature importance analysis saved to 'channel_importance.png'\")\n",
    "\n",
    "print(\"Additional visualization and analysis functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Normalizing data...\n",
      "Found 378 common samples between EMG and EEG data.\n",
      "Created 19576 windows from 378 samples.\n",
      "Number of classes: 7\n",
      "EMG windows shape: (19576, 50, 8)\n",
      "EEG windows shape: (19576, 50, 8)\n",
      "Training set: 11752 samples\n",
      "Validation set: 3900 samples\n",
      "Test set: 3924 samples\n",
      "Error occurred: name 'MultimodalNet' is not defined\n",
      "Multimodal neural network implementation complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\work\\AppData\\Local\\Temp\\ipykernel_7220\\2661198368.py\", line 88, in main\n",
      "    model = MultimodalNet(\n",
      "            ^^^^^^^^^^^^^\n",
      "NameError: name 'MultimodalNet' is not defined. Did you mean: 'MultimodalCNN'?\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        # Set paths to your data files\n",
    "        emg_path = 'data/processed/EMG-data.csv'\n",
    "        eeg_path = 'data/processed/EEG-data.csv'\n",
    "        \n",
    "        # Setup initial parameters\n",
    "        window_size = 50\n",
    "        batch_size = 32\n",
    "        learning_rate = 0.001\n",
    "        num_epochs = 30\n",
    "        warmup_epochs = 3\n",
    "        hidden_dim = 128\n",
    "\n",
    "        # Load and process data first\n",
    "        emg_windows, eeg_windows, window_labels, sample_ids = load_and_process_data(\n",
    "            emg_path, eeg_path, window_size=window_size\n",
    "        )\n",
    "        \n",
    "        # Get the dimensions from the data\n",
    "        emg_channels = emg_windows.shape[2]  # Should be 8\n",
    "        eeg_channels = eeg_windows.shape[2]  # Should be 8\n",
    "        num_classes = len(np.unique(window_labels))  # Should be 7\n",
    "        \n",
    "        print(f\"EMG channels: {emg_channels}\")\n",
    "        print(f\"EEG channels: {eeg_channels}\")\n",
    "        print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "        # Create train/val/test split\n",
    "        unique_samples = np.unique(sample_ids)\n",
    "        samples_train, samples_temp = train_test_split(\n",
    "            unique_samples, test_size=0.4, random_state=42\n",
    "        )\n",
    "        samples_val, samples_test = train_test_split(\n",
    "            samples_temp, test_size=0.5, random_state=42\n",
    "        )\n",
    "        \n",
    "        train_mask = np.isin(sample_ids, samples_train)\n",
    "        val_mask = np.isin(sample_ids, samples_val)\n",
    "        test_mask = np.isin(sample_ids, samples_test)\n",
    "        \n",
    "        # Split the data\n",
    "        X_emg_train = emg_windows[train_mask]\n",
    "        X_eeg_train = eeg_windows[train_mask]\n",
    "        y_train = window_labels[train_mask]\n",
    "        \n",
    "        X_emg_val = emg_windows[val_mask]\n",
    "        X_eeg_val = eeg_windows[val_mask]\n",
    "        y_val = window_labels[val_mask]\n",
    "        \n",
    "        X_emg_test = emg_windows[test_mask]\n",
    "        X_eeg_test = eeg_windows[test_mask]\n",
    "        y_test = window_labels[test_mask]\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = MultimodalDataset(X_emg_train, X_eeg_train, y_train)\n",
    "        val_dataset = MultimodalDataset(X_emg_val, X_eeg_val, y_val)\n",
    "        test_dataset = MultimodalDataset(X_emg_test, X_eeg_test, y_test)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True, \n",
    "            pin_memory=True, num_workers=0\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, batch_size=batch_size, shuffle=False,\n",
    "            pin_memory=True, num_workers=0\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=batch_size, shuffle=False,\n",
    "            pin_memory=True, num_workers=0\n",
    "        )\n",
    "        \n",
    "        # Initialize model with correct dimensions\n",
    "        model = MultimodalCNN(\n",
    "            emg_channels=emg_channels,\n",
    "            eeg_channels=eeg_channels,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_classes=num_classes\n",
    "        ).to(device)\n",
    "        \n",
    "        # Count parameters\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"Model has {total_params:,} parameters\")\n",
    "        \n",
    "        # Initialize training components\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs-warmup_epochs, eta_min=learning_rate/100)\n",
    "        \n",
    "        # Train the model\n",
    "        trained_model, history = train_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            num_epochs=num_epochs,\n",
    "            clip_grad=1.0,\n",
    "            warmup_epochs=warmup_epochs,\n",
    "            learning_rate=learning_rate\n",
    "        )\n",
    "        \n",
    "        print(\"Training completed!\")\n",
    "        \n",
    "        # Evaluate the model on test set\n",
    "        test_results = evaluate_model(model, test_loader)\n",
    "        \n",
    "        print(f\"Test F1 Score: {test_results['f1']:.4f}\")\n",
    "        print(f\"Test Accuracy: {test_results['accuracy']:.2f}%\")\n",
    "        \n",
    "        # Save final results\n",
    "        final_results = {\n",
    "            'test_results': test_results,\n",
    "            'history': history\n",
    "        }\n",
    "        np.save('final_results.npy', final_results)\n",
    "        \n",
    "        # Plot training history\n",
    "        plot_training_history(history)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(history['train_f1'], label='Train F1')\n",
    "    plt.plot(history['val_f1'], label='Validation F1')\n",
    "    plt.title('F1 Score over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(history['learning_rates'], label='Learning Rate')\n",
    "    plt.title('Learning Rate over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
