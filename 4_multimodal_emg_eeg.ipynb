{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal EMG-EEG Gesture Classification using Deep Learning\n",
    "implements a multimodal deep learning approach combining EMG and EEG data for gesture classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.amp import autocast, GradScaler\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "import random\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set memory optimization flags and reproducibility\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.empty_cache()\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "EMG_DATA_PATH = 'data/processed/EMG-data.csv'\n",
    "EEG_DATA_PATH = 'data/processed/EEG-data.csv'\n",
    "MODEL_SAVE_PATH = 'models/multimodal_eeg_emg.pth'\n",
    "\n",
    "\n",
    "# Create model directories if they don't exist\n",
    "os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
    "os.makedirs('models/multimodal_eeg_emg', exist_ok=True)\n",
    "\n",
    "\n",
    "# Data processing parameters\n",
    "DELTA_T = 35  # Time difference between EEG and EMG in ms\n",
    "WINDOW_SIZE = 200  # Window size for data processing\n",
    "\n",
    "# Model hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "INITIAL_LR = 0.001  # Initial learning rate\n",
    "MIN_LR = 1e-6      # Minimum learning rate\n",
    "WEIGHT_DECAY = 1e-5\n",
    "HIDDEN_DIM = 64\n",
    "\n",
    "# Training settings\n",
    "TRAIN_TEST_SPLIT = 0.2\n",
    "VALIDATION_SPLIT = 0.2\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Learning rate scheduler settings\n",
    "NUM_EPOCHS = 50  # Will run for full 100 epochs\n",
    "WARMUP_EPOCHS = 5\n",
    "CYCLES = 3  # Number of cosine annealing cycles\n",
    "CYCLE_LEN = NUM_EPOCHS // CYCLES  # Length of each cycle\n",
    "T_MULT = 2  # Factor to increase cycle length after each cycle\n",
    "ETA_MIN = MIN_LR  # Minimum learning rate for cosine annealing\n",
    "\n",
    "# Training improvements\n",
    "GRAD_CLIP_VAL = 1.0  # Gradient clipping value\n",
    "LABEL_SMOOTHING = 0.1  # Label smoothing factor\n",
    "NUM_CHECKPOINTS = 5  # Number of best checkpoints to save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(emg_path, eeg_path, window_size=WINDOW_SIZE):\n",
    "    print(\"Loading data...\")\n",
    "    \n",
    "    # Load data\n",
    "    emg_data = pd.read_csv(emg_path)\n",
    "    eeg_data = pd.read_csv(eeg_path)\n",
    "    \n",
    "    # Extract features and labels\n",
    "    emg_features = emg_data.iloc[:, :8].values  # 8 EMG channels\n",
    "    eeg_features = eeg_data.iloc[:, :8].values  # 8 EEG channels\n",
    "    \n",
    "    # Standardize features\n",
    "    print(\"Normalizing data...\")\n",
    "    emg_scaler = StandardScaler()\n",
    "    eeg_scaler = StandardScaler()\n",
    "    \n",
    "    emg_features = emg_scaler.fit_transform(emg_features)\n",
    "    eeg_features = eeg_scaler.fit_transform(eeg_features)\n",
    "    \n",
    "    # Create windowed data\n",
    "    emg_windows = []\n",
    "    eeg_windows = []\n",
    "    window_labels = []\n",
    "    sample_ids = []  # Track sample IDs for stratified splits\n",
    "    \n",
    "    # Find common samples between EMG and EEG data\n",
    "    emg_samples = set(tuple(x) for x in emg_data[['subject', 'repetition', 'gesture']].drop_duplicates().values)\n",
    "    eeg_samples = set(tuple(x) for x in eeg_data[['subject', 'repetition', 'gesture']].drop_duplicates().values)\n",
    "    common_samples = emg_samples.intersection(eeg_samples)\n",
    "    \n",
    "    print(f\"Found {len(common_samples)} common samples between EMG and EEG data.\")\n",
    "    \n",
    "    for sample in common_samples:\n",
    "        subject, repetition, gesture = sample\n",
    "        \n",
    "        # Get data for this sample\n",
    "        emg_sample = emg_data[(emg_data['subject'] == subject) & \n",
    "                             (emg_data['repetition'] == repetition) & \n",
    "                             (emg_data['gesture'] == gesture)]\n",
    "        \n",
    "        eeg_sample = eeg_data[(eeg_data['subject'] == subject) & \n",
    "                             (eeg_data['repetition'] == repetition) & \n",
    "                             (eeg_data['gesture'] == gesture)]\n",
    "        \n",
    "        # Make sure both samples have data\n",
    "        if len(emg_sample) == 0 or len(eeg_sample) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Extract features\n",
    "        emg_sample_features = emg_sample.iloc[:, :8].values\n",
    "        eeg_sample_features = eeg_sample.iloc[:, :8].values\n",
    "        \n",
    "        # Standardize using pre-fitted scalers\n",
    "        emg_sample_features = emg_scaler.transform(emg_sample_features)\n",
    "        eeg_sample_features = eeg_scaler.transform(eeg_sample_features)\n",
    "        \n",
    "        # Handle different lengths by using the shorter one\n",
    "        min_length = min(len(emg_sample_features), len(eeg_sample_features))\n",
    "        if min_length <= window_size:\n",
    "            continue  # Skip if sample is too short\n",
    "            \n",
    "        emg_sample_features = emg_sample_features[:min_length]\n",
    "        eeg_sample_features = eeg_sample_features[:min_length]\n",
    "        \n",
    "        # Create windows with fixed size\n",
    "        for i in range(0, min_length - window_size, window_size // 2):\n",
    "            emg_window = emg_sample_features[i:i + window_size]\n",
    "            eeg_window = eeg_sample_features[i:i + window_size]\n",
    "            \n",
    "            # Only add if window is complete\n",
    "            if len(emg_window) == window_size and len(eeg_window) == window_size:\n",
    "                # Transpose the windows to have shape (channels, time_steps)\n",
    "                emg_windows.append(emg_window.T)  # Shape: (8, window_size)\n",
    "                eeg_windows.append(eeg_window.T)  # Shape: (8, window_size)\n",
    "                window_labels.append(gesture - 1)  # 0-indexed labels\n",
    "                sample_ids.append(f\"{subject}_{repetition}_{gesture}\")\n",
    "    \n",
    "    if len(emg_windows) == 0:\n",
    "        raise ValueError(\"No valid windows could be created. Check your data alignment.\")\n",
    "    \n",
    "    print(f\"Created {len(emg_windows)} windows from {len(common_samples)} samples.\")\n",
    "    \n",
    "    # Convert to numpy arrays with explicit shape checking\n",
    "    emg_windows = np.array(emg_windows)  # Shape: (n_windows, n_channels, window_size)\n",
    "    eeg_windows = np.array(eeg_windows)  # Shape: (n_windows, n_channels, window_size)\n",
    "    window_labels = np.array(window_labels)\n",
    "    sample_ids = np.array(sample_ids)\n",
    "    \n",
    "    print(f\"EMG windows shape: {emg_windows.shape}\")\n",
    "    print(f\"EEG windows shape: {eeg_windows.shape}\")\n",
    "    \n",
    "    return emg_windows, eeg_windows, window_labels, sample_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=NUM_EPOCHS):\n",
    "    print(\"Starting training...\")\n",
    "    best_val_acc = 0.0\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for emg, eeg, labels in train_loader:\n",
    "            emg, eeg, labels = emg.to(device), eeg.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "                outputs = model(emg, eeg)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for emg, eeg, labels in val_loader:\n",
    "                emg, eeg, labels = emg.to(device), eeg.to(device), labels.to(device)\n",
    "                outputs = model(emg, eeg)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        train_acc = 100. * train_correct / train_total\n",
    "        val_acc = 100. * val_correct / val_total\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_acc:.2f}%, Val F1: {val_f1:.4f}')\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "            print(f'New best model saved with validation accuracy: {val_acc:.2f}%')\n",
    "        \n",
    "        print('-' * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, emg_data, eeg_data, labels, time_shift=DELTA_T):\n",
    "        # Data is already in shape (n_windows, n_channels, window_size)\n",
    "        self.emg_data = torch.FloatTensor(emg_data)\n",
    "        self.eeg_data = torch.FloatTensor(eeg_data)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        self.time_shift = time_shift\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Shift EMG data by DELTA_T\n",
    "        emg = self.emg_data[idx]  # Shape: (n_channels, window_size)\n",
    "        eeg = self.eeg_data[idx]  # Shape: (n_channels, window_size)\n",
    "        if self.time_shift > 0:\n",
    "            emg = F.pad(emg[:, self.time_shift:], (0, self.time_shift))\n",
    "        return emg, eeg, self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Architecture Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Conv1d(out_channels, out_channels*2, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(out_channels*2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class LateFusionCNN(nn.Module):\n",
    "    def __init__(self, emg_channels, eeg_channels, hidden_dim, num_classes):\n",
    "        super(LateFusionCNN, self).__init__()\n",
    "        \n",
    "        # EMG CNN Branch\n",
    "        self.emg_cnn = nn.Sequential(\n",
    "            CNNBlock(emg_channels, hidden_dim),\n",
    "            nn.Conv1d(hidden_dim*2, hidden_dim*4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(hidden_dim*4),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        # EEG CNN Branch\n",
    "        self.eeg_cnn = nn.Sequential(\n",
    "            CNNBlock(eeg_channels, hidden_dim),\n",
    "            nn.Conv1d(hidden_dim*2, hidden_dim*4, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(hidden_dim*4),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        # Late Fusion and Classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*8, hidden_dim*4),\n",
    "            nn.LayerNorm(hidden_dim*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(hidden_dim*4, hidden_dim*2),\n",
    "            nn.LayerNorm(hidden_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim*2, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Conv1d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        elif isinstance(m, nn.BatchNorm1d):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    def forward(self, emg, eeg):\n",
    "        # Extract features from each modality\n",
    "        emg_features = self.emg_cnn(emg)  # Shape: [batch, hidden_dim*4]\n",
    "        eeg_features = self.eeg_cnn(eeg)  # Shape: [batch, hidden_dim*4]\n",
    "        \n",
    "        # Concatenate features\n",
    "        combined = torch.cat((emg_features, eeg_features), dim=1)  # Shape: [batch, hidden_dim*8]\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(combined)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Model Architecture\n",
    "Implementation of the CNNLSTMFusion model combining EMG and EEG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTMFusion(nn.Module):\n",
    "    def __init__(self, emg_channels, eeg_channels, hidden_dim, num_classes):\n",
    "        super(CNNLSTMFusion, self).__init__()\n",
    "        \n",
    "        # CNN Encoders\n",
    "        self.emg_encoder = CNNEncoder(emg_channels, hidden_dim)\n",
    "        self.eeg_encoder = CNNEncoder(eeg_channels, hidden_dim)\n",
    "        \n",
    "        # LSTM layers\n",
    "        lstm_input_dim = hidden_dim * 8 * 2  # Combined features from both modalities\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_input_dim,\n",
    "            hidden_size=hidden_dim * 4,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.3,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Final classification layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 8, hidden_dim * 4),\n",
    "            nn.LayerNorm(hidden_dim * 4),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim * 2),\n",
    "            nn.LayerNorm(hidden_dim * 2),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim * 2, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, emg, eeg):\n",
    "        # Input shapes are already [batch, channels, sequence]\n",
    "        \n",
    "        # CNN feature extraction\n",
    "        emg_features = self.emg_encoder(emg)\n",
    "        eeg_features = self.eeg_encoder(eeg)\n",
    "        \n",
    "        # Combine features\n",
    "        combined = torch.cat((emg_features, eeg_features), dim=1)\n",
    "        \n",
    "        # Reshape for LSTM\n",
    "        batch_size = combined.size(0)\n",
    "        seq_len = combined.size(2)\n",
    "        combined = combined.permute(0, 2, 1)  # [batch, seq_len, features]\n",
    "        \n",
    "        # LSTM processing\n",
    "        lstm_out, _ = self.lstm(combined)\n",
    "        \n",
    "        # Take the last output\n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(lstm_out)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "Load and preprocess the EMG and EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Loading data...\n",
      "Normalizing data...\n",
      "Found 378 common samples between EMG and EEG data.\n",
      "Created 4517 windows from 378 samples.\n",
      "EMG windows shape: (4517, 8, 200)\n",
      "EEG windows shape: (4517, 8, 200)\n",
      "Data shapes:\n",
      "Training: EMG (2890, 8, 200), EEG (2890, 8, 200)\n",
      "Validation: EMG (723, 8, 200), EEG (723, 8, 200)\n",
      "Test: EMG (904, 8, 200), EEG (904, 8, 200)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading and preprocessing data...\")\n",
    "emg_data, eeg_data, labels, sample_ids = load_and_preprocess_data(\n",
    "    EMG_DATA_PATH,\n",
    "    EEG_DATA_PATH\n",
    ")\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "X_emg_train, X_emg_test, X_eeg_train, X_eeg_test, y_train, y_test = train_test_split(\n",
    "    emg_data, eeg_data, labels, \n",
    "    test_size=TRAIN_TEST_SPLIT, \n",
    "    random_state=RANDOM_SEED, \n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "X_emg_train, X_emg_val, X_eeg_train, X_eeg_val, y_train, y_val = train_test_split(\n",
    "    X_emg_train, X_eeg_train, y_train, \n",
    "    test_size=VALIDATION_SPLIT, \n",
    "    random_state=RANDOM_SEED, \n",
    "    stratify=y_train\n",
    ")\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(f\"Training: EMG {X_emg_train.shape}, EEG {X_eeg_train.shape}\")\n",
    "print(f\"Validation: EMG {X_emg_val.shape}, EEG {X_eeg_val.shape}\")\n",
    "print(f\"Test: EMG {X_emg_test.shape}, EEG {X_eeg_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Loaders\n",
    "Prepare data loaders for training, validation, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaders created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = MultimodalDataset(X_emg_train, X_eeg_train, y_train)\n",
    "val_dataset = MultimodalDataset(X_emg_val, X_eeg_val, y_val)\n",
    "test_dataset = MultimodalDataset(X_emg_test, X_eeg_test, y_test)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "Initialize the model, loss function, and optimizer with advanced learning rate scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully\n",
      "Number of classes: 7\n",
      "\n",
      "Model Architecture:\n",
      "LateFusionCNN(\n",
      "  (emg_cnn): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv1d(8, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (4): Dropout(p=0.2, inplace=False)\n",
      "        (5): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU()\n",
      "        (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (9): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): AdaptiveAvgPool1d(output_size=1)\n",
      "    (5): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (eeg_cnn): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv1d(8, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (4): Dropout(p=0.2, inplace=False)\n",
      "        (5): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU()\n",
      "        (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (9): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): AdaptiveAvgPool1d(output_size=1)\n",
      "    (5): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "num_classes = len(np.unique(labels))\n",
    "model = LateFusionCNN(\n",
    "    emg_channels=8,\n",
    "    eeg_channels=8,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_classes=num_classes\n",
    ").to(device)\n",
    "\n",
    "# Define loss and optimizer with improved settings\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=INITIAL_LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Define learning rate scheduler with cosine annealing and warm restarts\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=CYCLE_LEN,  # First cycle length\n",
    "    T_mult=T_MULT,  # Cycle length multiplication factor\n",
    "    eta_min=MIN_LR  # Minimum learning rate\n",
    ")\n",
    "\n",
    "print(\"Model initialized successfully\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "Train the model for full 100 epochs using advanced learning rate scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [1/100] | Train Loss: 2.4284, Train Acc: 15.85% | Val Loss: 2.3705, Val Acc: 16.87%, Val F1: 0.1176 | LR: 0.000000\n",
      "Saved checkpoint with validation accuracy: 16.87%\n",
      "New best model saved with validation accuracy: 16.87%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [2/100] | Train Loss: 1.8708, Train Acc: 31.14% | Val Loss: 1.4011, Val Acc: 50.35%, Val F1: 0.4904 | LR: 0.000095\n",
      "Saved checkpoint with validation accuracy: 50.35%\n",
      "New best model saved with validation accuracy: 50.35%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [3/100] | Train Loss: 1.4992, Train Acc: 47.37% | Val Loss: 1.1815, Val Acc: 63.76%, Val F1: 0.6387 | LR: 0.000345\n",
      "Saved checkpoint with validation accuracy: 63.76%\n",
      "New best model saved with validation accuracy: 63.76%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [4/100] | Train Loss: 1.3356, Train Acc: 57.09% | Val Loss: 1.0593, Val Acc: 70.40%, Val F1: 0.7146 | LR: 0.000655\n",
      "Saved checkpoint with validation accuracy: 70.40%\n",
      "New best model saved with validation accuracy: 70.40%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [5/100] | Train Loss: 1.1263, Train Acc: 67.61% | Val Loss: 0.9935, Val Acc: 74.55%, Val F1: 0.7444 | LR: 0.000905\n",
      "Saved checkpoint with validation accuracy: 74.55%\n",
      "New best model saved with validation accuracy: 74.55%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [6/100] | Train Loss: 1.0175, Train Acc: 73.56% | Val Loss: 0.8345, Val Acc: 83.82%, Val F1: 0.8358 | LR: 0.000905\n",
      "Saved checkpoint with validation accuracy: 83.82%\n",
      "New best model saved with validation accuracy: 83.82%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [7/100] | Train Loss: 0.9194, Train Acc: 78.65% | Val Loss: 0.8278, Val Acc: 80.50%, Val F1: 0.8047 | LR: 0.000998\n",
      "Saved checkpoint with validation accuracy: 80.50%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [8/100] | Train Loss: 0.8664, Train Acc: 80.73% | Val Loss: 0.7921, Val Acc: 84.23%, Val F1: 0.8423 | LR: 0.000991\n",
      "Saved checkpoint with validation accuracy: 84.23%\n",
      "New best model saved with validation accuracy: 84.23%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [9/100] | Train Loss: 0.7858, Train Acc: 85.40% | Val Loss: 0.7002, Val Acc: 89.76%, Val F1: 0.8961 | LR: 0.000980\n",
      "Saved checkpoint with validation accuracy: 89.76%\n",
      "New best model saved with validation accuracy: 89.76%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [10/100] | Train Loss: 0.7342, Train Acc: 87.30% | Val Loss: 0.6596, Val Acc: 90.59%, Val F1: 0.9050 | LR: 0.000964\n",
      "Saved checkpoint with validation accuracy: 90.59%\n",
      "New best model saved with validation accuracy: 90.59%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [11/100] | Train Loss: 0.7102, Train Acc: 90.00% | Val Loss: 0.6442, Val Acc: 91.98%, Val F1: 0.9200 | LR: 0.000944\n",
      "Saved checkpoint with validation accuracy: 91.98%\n",
      "New best model saved with validation accuracy: 91.98%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [12/100] | Train Loss: 0.6786, Train Acc: 91.56% | Val Loss: 0.6413, Val Acc: 91.70%, Val F1: 0.9162 | LR: 0.000921\n",
      "Saved checkpoint with validation accuracy: 91.70%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [13/100] | Train Loss: 0.6639, Train Acc: 91.38% | Val Loss: 0.6203, Val Acc: 92.12%, Val F1: 0.9206 | LR: 0.000893\n",
      "Saved checkpoint with validation accuracy: 92.12%\n",
      "New best model saved with validation accuracy: 92.12%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [14/100] | Train Loss: 0.6534, Train Acc: 91.90% | Val Loss: 0.5914, Val Acc: 94.19%, Val F1: 0.9418 | LR: 0.000862\n",
      "Saved checkpoint with validation accuracy: 94.19%\n",
      "New best model saved with validation accuracy: 94.19%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [15/100] | Train Loss: 0.6367, Train Acc: 92.56% | Val Loss: 0.5701, Val Acc: 95.16%, Val F1: 0.9508 | LR: 0.000828\n",
      "Saved checkpoint with validation accuracy: 95.16%\n",
      "New best model saved with validation accuracy: 95.16%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [16/100] | Train Loss: 0.6172, Train Acc: 94.01% | Val Loss: 0.5676, Val Acc: 95.99%, Val F1: 0.9597 | LR: 0.000790\n",
      "Saved checkpoint with validation accuracy: 95.99%\n",
      "New best model saved with validation accuracy: 95.99%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [17/100] | Train Loss: 0.5947, Train Acc: 94.88% | Val Loss: 0.5489, Val Acc: 95.71%, Val F1: 0.9569 | LR: 0.000750\n",
      "Saved checkpoint with validation accuracy: 95.71%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [18/100] | Train Loss: 0.5857, Train Acc: 94.78% | Val Loss: 0.5448, Val Acc: 96.54%, Val F1: 0.9654 | LR: 0.000708\n",
      "Saved checkpoint with validation accuracy: 96.54%\n",
      "New best model saved with validation accuracy: 96.54%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [19/100] | Train Loss: 0.5939, Train Acc: 94.74% | Val Loss: 0.5876, Val Acc: 93.78%, Val F1: 0.9376 | LR: 0.000664\n",
      "[Multimodal EEG-EMG] Epoch [20/100] | Train Loss: 0.5776, Train Acc: 95.61% | Val Loss: 0.5607, Val Acc: 94.74%, Val F1: 0.9471 | LR: 0.000618\n",
      "Saved checkpoint with validation accuracy: 94.74%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [21/100] | Train Loss: 0.5796, Train Acc: 95.36% | Val Loss: 0.5148, Val Acc: 97.79%, Val F1: 0.9779 | LR: 0.000572\n",
      "Saved checkpoint with validation accuracy: 97.79%\n",
      "New best model saved with validation accuracy: 97.79%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [22/100] | Train Loss: 0.5640, Train Acc: 95.92% | Val Loss: 0.5443, Val Acc: 95.71%, Val F1: 0.9569 | LR: 0.000524\n",
      "Saved checkpoint with validation accuracy: 95.71%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [23/100] | Train Loss: 0.5438, Train Acc: 97.30% | Val Loss: 0.5158, Val Acc: 97.23%, Val F1: 0.9721 | LR: 0.000477\n",
      "Saved checkpoint with validation accuracy: 97.23%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [24/100] | Train Loss: 0.5462, Train Acc: 96.99% | Val Loss: 0.5602, Val Acc: 95.16%, Val F1: 0.9516 | LR: 0.000429\n",
      "[Multimodal EEG-EMG] Epoch [25/100] | Train Loss: 0.5356, Train Acc: 97.65% | Val Loss: 0.5060, Val Acc: 97.65%, Val F1: 0.9765 | LR: 0.000383\n",
      "Saved checkpoint with validation accuracy: 97.65%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [26/100] | Train Loss: 0.5362, Train Acc: 97.75% | Val Loss: 0.5115, Val Acc: 97.51%, Val F1: 0.9750 | LR: 0.000337\n",
      "Saved checkpoint with validation accuracy: 97.51%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [27/100] | Train Loss: 0.5329, Train Acc: 97.65% | Val Loss: 0.5163, Val Acc: 97.23%, Val F1: 0.9724 | LR: 0.000293\n",
      "Saved checkpoint with validation accuracy: 97.23%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [28/100] | Train Loss: 0.5248, Train Acc: 98.03% | Val Loss: 0.5034, Val Acc: 97.93%, Val F1: 0.9792 | LR: 0.000251\n",
      "Saved checkpoint with validation accuracy: 97.93%\n",
      "New best model saved with validation accuracy: 97.93%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [29/100] | Train Loss: 0.5257, Train Acc: 97.82% | Val Loss: 0.5110, Val Acc: 97.51%, Val F1: 0.9750 | LR: 0.000211\n",
      "Saved checkpoint with validation accuracy: 97.51%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [30/100] | Train Loss: 0.5249, Train Acc: 97.96% | Val Loss: 0.4966, Val Acc: 98.76%, Val F1: 0.9876 | LR: 0.000173\n",
      "Saved checkpoint with validation accuracy: 98.76%\n",
      "New best model saved with validation accuracy: 98.76%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [31/100] | Train Loss: 0.5172, Train Acc: 98.41% | Val Loss: 0.4960, Val Acc: 98.06%, Val F1: 0.9806 | LR: 0.000139\n",
      "Saved checkpoint with validation accuracy: 98.06%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [32/100] | Train Loss: 0.5120, Train Acc: 98.72% | Val Loss: 0.4948, Val Acc: 98.34%, Val F1: 0.9834 | LR: 0.000108\n",
      "Saved checkpoint with validation accuracy: 98.34%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [33/100] | Train Loss: 0.5129, Train Acc: 98.69% | Val Loss: 0.4852, Val Acc: 98.62%, Val F1: 0.9861 | LR: 0.000080\n",
      "Saved checkpoint with validation accuracy: 98.62%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [34/100] | Train Loss: 0.5100, Train Acc: 98.69% | Val Loss: 0.4859, Val Acc: 99.17%, Val F1: 0.9917 | LR: 0.000057\n",
      "Saved checkpoint with validation accuracy: 99.17%\n",
      "New best model saved with validation accuracy: 99.17%\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [35/100] | Train Loss: 0.5070, Train Acc: 98.72% | Val Loss: 0.4854, Val Acc: 99.03%, Val F1: 0.9903 | LR: 0.000037\n",
      "Saved checkpoint with validation accuracy: 99.03%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [36/100] | Train Loss: 0.5058, Train Acc: 98.89% | Val Loss: 0.4934, Val Acc: 98.34%, Val F1: 0.9834 | LR: 0.000021\n",
      "Saved checkpoint with validation accuracy: 98.34%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [37/100] | Train Loss: 0.5041, Train Acc: 99.24% | Val Loss: 0.4859, Val Acc: 99.03%, Val F1: 0.9903 | LR: 0.000010\n",
      "Saved checkpoint with validation accuracy: 99.03%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [38/100] | Train Loss: 0.5011, Train Acc: 99.20% | Val Loss: 0.4839, Val Acc: 99.03%, Val F1: 0.9903 | LR: 0.000003\n",
      "Saved checkpoint with validation accuracy: 99.03%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [39/100] | Train Loss: 0.5844, Train Acc: 95.74% | Val Loss: 0.5063, Val Acc: 98.48%, Val F1: 0.9848 | LR: 0.001000\n",
      "[Multimodal EEG-EMG] Epoch [40/100] | Train Loss: 0.5824, Train Acc: 95.09% | Val Loss: 0.5805, Val Acc: 94.74%, Val F1: 0.9476 | LR: 0.000999\n",
      "[Multimodal EEG-EMG] Epoch [41/100] | Train Loss: 0.5707, Train Acc: 95.99% | Val Loss: 0.5123, Val Acc: 97.10%, Val F1: 0.9710 | LR: 0.000998\n",
      "[Multimodal EEG-EMG] Epoch [42/100] | Train Loss: 0.5815, Train Acc: 95.22% | Val Loss: 0.5656, Val Acc: 94.47%, Val F1: 0.9443 | LR: 0.000995\n",
      "[Multimodal EEG-EMG] Epoch [43/100] | Train Loss: 0.5673, Train Acc: 96.09% | Val Loss: 0.5800, Val Acc: 94.05%, Val F1: 0.9404 | LR: 0.000991\n",
      "[Multimodal EEG-EMG] Epoch [44/100] | Train Loss: 0.5644, Train Acc: 95.78% | Val Loss: 0.5188, Val Acc: 97.51%, Val F1: 0.9752 | LR: 0.000986\n",
      "[Multimodal EEG-EMG] Epoch [45/100] | Train Loss: 0.5613, Train Acc: 95.99% | Val Loss: 0.5179, Val Acc: 97.37%, Val F1: 0.9735 | LR: 0.000980\n",
      "[Multimodal EEG-EMG] Epoch [46/100] | Train Loss: 0.5509, Train Acc: 96.57% | Val Loss: 0.5037, Val Acc: 97.93%, Val F1: 0.9792 | LR: 0.000973\n",
      "[Multimodal EEG-EMG] Epoch [47/100] | Train Loss: 0.5408, Train Acc: 97.13% | Val Loss: 0.5068, Val Acc: 97.79%, Val F1: 0.9779 | LR: 0.000964\n",
      "[Multimodal EEG-EMG] Epoch [48/100] | Train Loss: 0.5412, Train Acc: 97.06% | Val Loss: 0.4930, Val Acc: 98.48%, Val F1: 0.9848 | LR: 0.000955\n",
      "[Multimodal EEG-EMG] Epoch [49/100] | Train Loss: 0.5387, Train Acc: 97.02% | Val Loss: 0.4887, Val Acc: 98.76%, Val F1: 0.9875 | LR: 0.000944\n",
      "Saved checkpoint with validation accuracy: 98.76%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [50/100] | Train Loss: 0.5302, Train Acc: 97.68% | Val Loss: 0.5023, Val Acc: 97.51%, Val F1: 0.9751 | LR: 0.000933\n",
      "[Multimodal EEG-EMG] Epoch [51/100] | Train Loss: 0.5225, Train Acc: 97.79% | Val Loss: 0.4886, Val Acc: 98.76%, Val F1: 0.9876 | LR: 0.000921\n",
      "Saved checkpoint with validation accuracy: 98.76%\n",
      "\n",
      "[Multimodal EEG-EMG] Epoch [52/100] | Train Loss: 0.5337, Train Acc: 97.37% | Val Loss: 0.5125, Val Acc: 96.96%, Val F1: 0.9695 | LR: 0.000907\n",
      "[Multimodal EEG-EMG] Epoch [53/100] | Train Loss: 0.5142, Train Acc: 98.20% | Val Loss: 0.4825, Val Acc: 98.62%, Val F1: 0.9861 | LR: 0.000893\n",
      "[Multimodal EEG-EMG] Epoch [54/100] | Train Loss: 0.5246, Train Acc: 97.61% | Val Loss: 0.4934, Val Acc: 98.34%, Val F1: 0.9834 | LR: 0.000878\n",
      "[Multimodal EEG-EMG] Epoch [55/100] | Train Loss: 0.5087, Train Acc: 98.27% | Val Loss: 0.4992, Val Acc: 98.34%, Val F1: 0.9834 | LR: 0.000862\n",
      "[Multimodal EEG-EMG] Epoch [56/100] | Train Loss: 0.5247, Train Acc: 97.30% | Val Loss: 0.5660, Val Acc: 93.64%, Val F1: 0.9361 | LR: 0.000845"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m         param_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m current_lr\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m emg, eeg, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     39\u001b[0m     emg, eeg, labels \u001b[38;5;241m=\u001b[39m emg\u001b[38;5;241m.\u001b[39mto(device), eeg\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     41\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# More efficient than zero_grad()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\work\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\work\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\work\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[25], line 22\u001b[0m, in \u001b[0;36mMultimodalDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     20\u001b[0m eeg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meeg_data[idx]  \u001b[38;5;66;03m# Shape: (n_channels, window_size)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_shift \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 22\u001b[0m     emg \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(emg[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_shift:], (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_shift))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m emg, eeg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n",
      "File \u001b[1;32mc:\\Users\\work\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:5209\u001b[0m, in \u001b[0;36mpad\u001b[1;34m(input, pad, mode, value)\u001b[0m\n\u001b[0;32m   5202\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplicate\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   5203\u001b[0m             \u001b[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put.\u001b[39;00m\n\u001b[0;32m   5204\u001b[0m             \u001b[38;5;66;03m# importlib is required because the import cannot be top level\u001b[39;00m\n\u001b[0;32m   5205\u001b[0m             \u001b[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001b[39;00m\n\u001b[0;32m   5206\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\n\u001b[0;32m   5207\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch._decomp.decompositions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5208\u001b[0m             )\u001b[38;5;241m.\u001b[39m_replication_pad(\u001b[38;5;28minput\u001b[39m, pad)\n\u001b[1;32m-> 5209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, pad, mode, value)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Starting training...\")\n",
    "best_val_acc = 0.0\n",
    "best_epoch = 0\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_acc': [],\n",
    "    'lr': [],\n",
    "    'val_f1': []  # Added F1 score tracking\n",
    "}\n",
    "\n",
    "# Keep track of best checkpoints\n",
    "best_checkpoints = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    # Warmup learning rate for first few epochs with cosine schedule\n",
    "    if epoch < WARMUP_EPOCHS:\n",
    "        progress = epoch / WARMUP_EPOCHS\n",
    "        warmup_factor = 0.5 * (1 + np.cos(np.pi * (1 - progress)))\n",
    "        current_lr = INITIAL_LR * warmup_factor\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = current_lr\n",
    "    \n",
    "    # Training phase\n",
    "    for emg, eeg, labels in train_loader:\n",
    "        emg, eeg, labels = emg.to(device), eeg.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)  # More efficient than zero_grad()\n",
    "        \n",
    "        with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "            outputs = model(emg, eeg)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP_VAL)\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for emg, eeg, labels in val_loader:\n",
    "            emg, eeg, labels = emg.to(device), eeg.to(device), labels.to(device)\n",
    "            outputs = model(emg, eeg)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    train_acc = 100. * train_correct / train_total\n",
    "    val_acc = 100. * val_correct / val_total\n",
    "    val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Update learning rate scheduler after warmup\n",
    "    if epoch >= WARMUP_EPOCHS:\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    \n",
    "    # Print progress\n",
    "    print()\n",
    "    print(f'[Multimodal EEG-EMG] Epoch [{epoch+1}/{NUM_EPOCHS}] | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, Val F1: {val_f1:.4f} | LR: {current_lr:.6f}', end='')\n",
    "\n",
    "\n",
    "    # Save checkpoint\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'val_acc': val_acc,\n",
    "        'val_f1': val_f1,\n",
    "        'history': history\n",
    "    }\n",
    "    \n",
    "    # Update best checkpoints list\n",
    "    best_checkpoints.append((val_acc, epoch, checkpoint))\n",
    "    best_checkpoints.sort(reverse=True)  # Sort by validation accuracy\n",
    "    best_checkpoints = best_checkpoints[:NUM_CHECKPOINTS]  # Keep top N checkpoints\n",
    "    \n",
    "    # Save if it's among the best checkpoints\n",
    "    if (val_acc, epoch) >= (best_checkpoints[-1][0], best_checkpoints[-1][1]):\n",
    "        torch.save(checkpoint, f\"models/multimodal_eeg_emg/checkpoint_{len(best_checkpoints)}.pth\")\n",
    "        print()\n",
    "        print(f'Saved checkpoint with validation accuracy: {val_acc:.2f}%')\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch\n",
    "            torch.save(checkpoint, MODEL_SAVE_PATH)\n",
    "            print(f'New best model saved with validation accuracy: {val_acc:.2f}%')\n",
    "            print('-' * 60)\n",
    "    \n",
    "    \n",
    "\n",
    "print(f\"Best model was saved at epoch {best_epoch+1} with validation accuracy: {best_val_acc:.2f}%\")\n",
    "print(\"\\nTop 5 best checkpoints:\")\n",
    "for i, (acc, epoch, _) in enumerate(best_checkpoints, 1):\n",
    "    print(f\"{i}. Epoch {epoch+1}: {acc:.2f}%\")\n",
    "\n",
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 10))  # Adjusted figure size for better 2x2 layout\n",
    "\n",
    "# Plot accuracies (top left)\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history['train_acc'], label='Train Acc')\n",
    "plt.plot(history['val_acc'], label='Val Acc')\n",
    "plt.title('Accuracy History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "# Plot losses (top right)\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot F1 scores (bottom left)\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(history['val_f1'], label='Validation F1')\n",
    "plt.title('F1 Score History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "\n",
    "# Plot learning rate (bottom right)\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(history['lr'])\n",
    "plt.title('Learning Rate Schedule')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Training completed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluate the best model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating best model on test set...\n",
      "\n",
      "Test Accuracy: 99.23%\n",
      "Test F1 Score: 0.9922\n",
      "\n",
      "Confusion Matrix:\n",
      "[[130   0   0   0   0   0   0]\n",
      " [  0 125   2   0   0   0   0]\n",
      " [  0   0 128   0   0   0   0]\n",
      " [  0   0   1 125   0   2   1]\n",
      " [  0   0   0   0 130   0   0]\n",
      " [  0   0   0   0   0 129   1]\n",
      " [  0   0   0   0   0   0 130]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating best model on test set...\")\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH, weights_only=False)['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for emg, eeg, labels in test_loader:\n",
    "        emg, eeg, labels = emg.to(device), eeg.to(device), labels.to(device)\n",
    "        outputs = model(emg, eeg)\n",
    "        _, predicted = outputs.max(1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_acc = 100. * test_correct / test_total\n",
    "test_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "print(f'\\nTest Accuracy: {test_acc:.2f}%')\n",
    "print(f'Test F1 Score: {test_f1:.4f}')\n",
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(all_labels, all_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
