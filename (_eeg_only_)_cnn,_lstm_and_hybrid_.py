# -*- coding: utf-8 -*-
"""( EEG only ) CNN, LSTM and Hybrid .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SLbNSSHUTbUw_yoaQvWRAiZtniPDxm0p

#EEG-Based Gesture Classification Using CNN, LSTM, and Hybrid CNN-LSTM Models

##Prepare the Models
"""

import os
import re
import numpy as np
import pandas as pd

from tqdm import tqdm

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.utils import to_categorical

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

import matplotlib.pyplot as plt

# Data Source and Usage:
# The dataset used is sourced from Mendeley Data, specifically the "8-channel EMG, EEG upper limb gesture data"
# (DOI: 10.17632/m6t78vngbt.1), published by Mustapha Dere on 10 December 2022. For this analysis, only the EMG
# component of the dataset was utilized, which is intended for intuitive control of a rehabilitation device.
# The data files are hosted on Google Colab and accessed from the following directory on Google Drive:
root_folder = "/content/drive/MyDrive/eeg_csv_data"

"""###Dataset

Data Aggregation and Initial Preprocessing
"""

def parse_filename(filename):
    """
    Extracts subject, repetition, and gesture details from a filename.
    Example format: 'S1_R1_G1.csv'
    Returns tuple of integers (subject, repetition, gesture) if match found, else (None, None, None).
    """
    match = re.match(r"S(\d+)_R(\d+)_G(\d+)\.csv", filename)
    return (int(match.group(1)), int(match.group(2)), int(match.group(3))) if match else (None, None, None)

def aggregate_data(root_folder, output_file="EEG-data.csv"):
    """
    Aggregates EEG data from CSV files inside each subject's folder,
    transposes each CSV (since rows represent channels and columns represent time samples),
    renames columns to "Channel_1", "Channel_2", etc.,
    and adds subject, gesture, and repetition information.
    Saves the combined DataFrame to a CSV file.
    """
    all_dfs = []
    file_list = []

    # Collect all valid CSV files
    for subject_folder in os.listdir(root_folder):
        subject_path = os.path.join(root_folder, subject_folder)
        if os.path.isdir(subject_path):
            for fname in os.listdir(subject_path):
                if fname.endswith(".csv"):
                    sub_id, rep, gest = parse_filename(fname)
                    if sub_id is not None:
                        file_list.append((subject_path, fname, sub_id, rep, gest))

    # Process files with a progress bar
    for subject_path, fname, sub_id, rep, gest in tqdm(file_list, desc="Processing EEG files", unit="file"):
        file_path = os.path.join(subject_path, fname)
        try:
            # Read the CSV file (assuming a header is present)
            df = pd.read_csv(file_path, header=0)
            # Transpose the DataFrame so rows become time samples and columns become channels
            df = df.T
            # Rename columns to match expected format (e.g., Channel_1, Channel_2, etc.)
            df.columns = [f"Channel_{i+1}" for i in range(df.shape[1])]
            # Add metadata columns to each time sample
            df["subject"] = sub_id
            df["gesture"] = gest
            df["repetition"] = rep
            all_dfs.append(df)
        except Exception as e:
            print(f"Error processing {file_path}: {e}")

    # Combine all DataFrames and save to a CSV file
    if all_dfs:
        combined_df = pd.concat(all_dfs, ignore_index=True)
        combined_df.to_csv(output_file, index=False)
        print(f"Saved combined EEG data to {output_file}")
        print("Combined DataFrame shape:", combined_df.shape)
        print(combined_df.head())
    else:
        print("No valid data files found.")

aggregate_data(root_folder)

"""Data Preparation"""

# Load the dataset from a CSV file.
df = pd.read_csv("EEG-data.csv")

# Adjust gesture labels to be zero-indexed
df['gesture'] = df['gesture'] - 1

# Define helper function to print in color
def print_color(text, color):
    """Prints text in specified ANSI color."""
    colors = {
        "red": "\033[91m",
        "green": "\033[92m",
        "yellow": "\033[93m",
        "blue": "\033[94m",
        "magenta": "\033[95m"
    }
    print(f"{colors[color]}{text}\033[0m")

# Display initial data and dataset structure.
print_color("Head of DataFrame:", "green")
print(df.head())
print_color("Shape of DataFrame:", "green")
print(df.shape)

# Check and display any null values in the dataset.
null_count = df.isnull().sum()
print_color("Null values in each column:", "yellow")
print(null_count)

# List and display unique gestures and subjects to understand data categories.
print_color("Unique gestures (after adjustment to 0-index):", "blue")
print(sorted(df["gesture"].unique()))
print_color("Unique subjects :", "blue")
print(sorted(df["subject"].unique()))

# Windowing Setup
# Set window size and step size for slicing the data.
WINDOW_SIZE = 100  # Number of samples per window.
STEP_SIZE = 50     # Interval at which new windows are created.

# Initialize lists to store windowed data and corresponding labels.
X_list = []
y_list = []

# Group the data by gesture, extracting features for each gesture.
for gesture_id in sorted(df["gesture"].unique()):
    gesture_df = df[df["gesture"] == gesture_id]
    gesture_data = gesture_df[
        ["Channel_1", "Channel_2", "Channel_3", "Channel_4",
         "Channel_5", "Channel_6", "Channel_7", "Channel_8"]
    ].values  # Extract channel data as numpy array.

    # Generate overlapping windows of data.
    for start_idx in range(0, len(gesture_data) - WINDOW_SIZE + 1, STEP_SIZE):
        window_data = gesture_data[start_idx:start_idx + WINDOW_SIZE]
        X_list.append(window_data)
        y_list.append(gesture_id)

# Convert lists to numpy arrays for model processing.
X_array = np.array(X_list)
y_array = np.array(y_list)

np.save("X_eeg.npy", X_array)
np.save("y_eeg.npy", y_array)


# Display shapes of the prepared datasets.
print_color("Shape of X_array:", "red")
print(X_array.shape)
print_color("Shape of y_array:", "red")
print(y_array.shape)

# Print statistics about the data in X_array
print_color("Data statistics in X_array:", "green")
print("Mean:", np.mean(X_array, axis=(0, 1)))  # Mean across all windows and all samples within each window
print("Standard Deviation:", np.std(X_array, axis=(0, 1)))  # Standard deviation across all windows and samples
print("Max value:", np.max(X_array))
print("Min value:", np.min(X_array))

"""Data Visualization"""

# Filter the DataFrame for Subject 1, Gesture 1, Repetition 1
filtered_df = df[(df['subject'] == 1) & (df['gesture'] == 1) & (df['repetition'] == 1)]

# Plot each EMG channel
plt.figure(figsize=(12, 16))
for i in range(1, 9):
    plt.subplot(8, 1, i)
    plt.plot(filtered_df[f'Channel_{i}'])
    plt.title(f'Channel {i}')
    plt.xlabel('Sample')
    plt.ylabel('Amplitude')

plt.tight_layout()
plt.show()

"""Split Data into Training and Testing Sets"""

# Split the windowed data into 80% training and 20% testing sets, ensuring reproducibility with a fixed random state.
x_train, x_test, y_train, y_test = train_test_split(X_array, y_array, test_size=0.2, random_state=42)

# Output the shapes of the training and testing datasets to verify the split.
print("x_train shape:", x_train.shape)
print("y_train shape:", y_train.shape)
print("x_test shape:", x_test.shape)
print("y_test shape:", y_test.shape)

"""Normalize Data (Optionally Per Channel)"""

# Reshape the training and testing data to flatten the windows for easier normalization calculations.
train_reshaped = x_train.reshape(-1, x_train.shape[-1])  # Flattens the training data.
test_reshaped = x_test.reshape(-1, x_test.shape[-1])     # Flattens the testing data.

# Calculate mean and standard deviation from the training data to prevent data leakage.
mean = train_reshaped.mean(axis=0)
std = train_reshaped.std(axis=0)
std[std == 0] = 1.0  # Avoid division by zero by setting zero standard deviations to one.

# Normalize training and testing data using the calculated mean and standard deviation.
train_reshaped = (train_reshaped - mean) / std
test_reshaped = (test_reshaped - mean) / std

# Reshape the data back to its original windowed format.
x_train_norm = train_reshaped.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2])
x_test_norm = test_reshaped.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2])

# Print the shapes of the normalized datasets to confirm the dimensions are maintained.
print("x_train_norm shape:", x_train_norm.shape)
print("x_test_norm shape:", x_test_norm.shape)

print("x_train_norm shape:", y_train.shape)
print("x_test_norm shape:", y_test.shape)

"""Convert labels to one-hot encoding"""

num_classes = df['gesture'].nunique()

# Output the shapes to verify correct dimensions
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

# Convert class vectors to binary class matrices
y_train_oh = to_categorical(y_train, num_classes=num_classes)
y_test_oh = to_categorical(y_test, num_classes=num_classes)

# Output the shapes to verify correct dimensions
print("y_train_oh shape:", y_train_oh.shape)
print("y_test_oh shape:", y_test_oh.shape)

print("Example one-hot label from y_test_oh:", y_test_oh[-1, :])

"""###1D CNN, LSTM and hybrid CNN-LSTM models

1D CNN model
"""

def build_cnn_1d_model(win_size, num_channels, num_classes):
    """
    Builds a 1D Convolutional Neural Network for EMG time-series data.

    Args:
        win_size (int): Number of time steps in each window (e.g., 100).
        num_channels (int): Number of EMG channels (e.g., 8).
        num_classes (int): Number of gesture classes.

    Returns:
        model (tf.keras.Model): Compiled 1D CNN model.
    """
    model = models.Sequential()

    # Convolution Block 1
    model.add(layers.Conv1D(filters=32, kernel_size=3, padding='same',
                            input_shape=(win_size, num_channels)))
    model.add(layers.BatchNormalization())
    model.add(layers.ReLU())
    model.add(layers.MaxPooling1D(pool_size=2))
    model.add(layers.Dropout(0.2))

    # Convolution Block 2
    model.add(layers.Conv1D(filters=64, kernel_size=3, padding='same'))
    model.add(layers.BatchNormalization())
    model.add(layers.ReLU())
    model.add(layers.MaxPooling1D(pool_size=2))
    model.add(layers.Dropout(0.2))

    # Flatten + Dense Layers
    model.add(layers.Flatten())
    model.add(layers.Dense(128, activation='relu'))
    model.add(layers.Dropout(0.3))

    # Output Layer
    model.add(layers.Dense(num_classes, activation='softmax'))

    # Compile Model
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

"""LSTM model"""

def build_lstm_model(win_size, num_channels, num_classes):
    """
    Builds a stacked LSTM network for EMG time-series data.

    Args:
        win_size (int): Number of time steps in each window (e.g., 100).
        num_channels (int): Number of EMG channels (e.g., 8).
        num_classes (int): Number of gesture classes.

    Returns:
        model (tf.keras.Model): Compiled LSTM model.
    """
    model = models.Sequential()

    # First LSTM Layer
    model.add(layers.LSTM(64, return_sequences=True,
                          input_shape=(win_size, num_channels)))
    model.add(layers.Dropout(0.2))

    # Second LSTM Layer
    model.add(layers.LSTM(64))
    model.add(layers.Dropout(0.2))

    # Dense + Output Layer
    model.add(layers.Dense(128, activation='relu'))
    model.add(layers.Dropout(0.3))
    model.add(layers.Dense(num_classes, activation='softmax'))

    # Compile Model
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

"""CNN + LSTM Model"""

def build_cnn_lstm_model(win_size, num_channels, num_classes):
    """
    Builds a hybrid CNN-LSTM model for EMG time-series data.

    Args:
        win_size (int): Number of time steps in each window (e.g., 100).
        num_channels (int): Number of EMG channels (e.g., 8).
        num_classes (int): Number of gesture classes.

    Returns:
        model (tf.keras.Model): Compiled CNN-LSTM model.
    """
    model = models.Sequential()

    # --- CNN Block ---
    model.add(layers.Conv1D(filters=32, kernel_size=3, padding='same',
                            input_shape=(win_size, num_channels)))
    model.add(layers.BatchNormalization())
    model.add(layers.ReLU())
    model.add(layers.MaxPooling1D(pool_size=2))
    model.add(layers.Dropout(0.2))

    model.add(layers.Conv1D(filters=64, kernel_size=3, padding='same'))
    model.add(layers.BatchNormalization())
    model.add(layers.ReLU())
    model.add(layers.MaxPooling1D(pool_size=2))
    model.add(layers.Dropout(0.2))

    # At this point, the shape is (batch, new_time_steps, 64)
    # Flattening entirely would remove the time dimension, so instead we pass it to LSTM:

    # --- Recurrent Block ---
    model.add(layers.LSTM(64, return_sequences=False))
    # You could also stack more LSTM layers:
    # e.g., model.add(layers.LSTM(64, return_sequences=False))

    model.add(layers.Dropout(0.3))

    # --- Dense Output Layer ---
    model.add(layers.Dense(128, activation='relu'))
    model.add(layers.Dropout(0.3))
    model.add(layers.Dense(num_classes, activation='softmax'))

    # Compile the model
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

"""###Train and Evaluate"""

EPOCHS = 100
BATCH_SIZE = 32

"""Train and Evaluate 1D CNN"""

# Build the CNN model
cnn_model = build_cnn_1d_model(
    win_size=x_train_norm.shape[1],   # e.g., 100
    num_channels=x_train_norm.shape[2],
    num_classes=y_train_oh.shape[1]   # e.g., 8
)

# Summarize the model
cnn_model.summary()

# Train the CNN
history_cnn = cnn_model.fit(
    x_train_norm, y_train_oh,
    validation_split=0.2,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1
)

# Evaluate on test set
test_loss_cnn, test_acc_cnn = cnn_model.evaluate(x_test_norm, y_test_oh, verbose=0)
print(f"1D CNN Test Accuracy: {test_acc_cnn:.4f}")
print(f"1D CNN Test Loss: {test_loss_cnn:.4f}")

# Generate predictions for classification report
y_pred_cnn = cnn_model.predict(x_test_norm, verbose=0)
y_pred_cnn_classes = np.argmax(y_pred_cnn, axis=1)
y_true_classes = np.argmax(y_test_oh, axis=1)

# Print classification report
print("\nClassification Report (1D CNN):")
print(classification_report(y_true_classes, y_pred_cnn_classes))

# (Optional) Print confusion matrix
print("Confusion Matrix (1D CNN):")
print(confusion_matrix(y_true_classes, y_pred_cnn_classes))

"""Train and Evaluate LSTM"""

# Build the LSTM model
lstm_model = build_lstm_model(
    win_size=x_train_norm.shape[1],   # e.g., 100
    num_channels=x_train_norm.shape[2],
    num_classes=y_train_oh.shape[1]   # e.g., 8
)

# Summarize the model
lstm_model.summary()

# Train the LSTM
history_lstm = lstm_model.fit(
    x_train_norm, y_train_oh,
    validation_split=0.2,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1
)

# Evaluate on test set
test_loss_lstm, test_acc_lstm = lstm_model.evaluate(x_test_norm, y_test_oh, verbose=0)
print(f"LSTM Test Accuracy: {test_acc_lstm:.4f}")
print(f"LSTM Test Loss: {test_loss_lstm:.4f}")

# Generate predictions for classification report
y_pred_lstm = lstm_model.predict(x_test_norm, verbose=0)
y_pred_lstm_classes = np.argmax(y_pred_lstm, axis=1)
y_true_classes = np.argmax(y_test_oh, axis=1)

# Print classification report
print("\nClassification Report (LSTM):")
print(classification_report(y_true_classes, y_pred_lstm_classes))

# (Optional) Print confusion matrix
print("Confusion Matrix (LSTM):")
print(confusion_matrix(y_true_classes, y_pred_lstm_classes))

"""Train and Evaluate CNN + LSTM"""

# Example: after you've prepared your data in (samples, time_steps, channels)
# e.g., x_train_norm, x_test_norm, y_train_oh, y_test_oh

# Build the CNN-LSTM model
hybrid_model = build_cnn_lstm_model(
    win_size=x_train_norm.shape[1],       # e.g., 100
    num_channels=x_train_norm.shape[2],   # e.g., 8
    num_classes=y_train_oh.shape[1]       # e.g., 8
)

hybrid_model.summary()


# Train the CNN-LSTM
history_hybrid = hybrid_model.fit(
    x_train_norm, y_train_oh,
    validation_split=0.2,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    verbose=1
)

# Evaluate on the test set
test_loss_hybrid, test_acc_hybrid = hybrid_model.evaluate(x_test_norm, y_test_oh, verbose=0)
print(f"CNN+LSTM Test Accuracy: {test_acc_hybrid:.4f}")
print(f"CNN+LSTM Test Loss: {test_loss_hybrid:.4f}")

y_pred_hybrid = hybrid_model.predict(x_test_norm)
y_pred_hybrid_classes = np.argmax(y_pred_hybrid, axis=1)
y_true_classes = np.argmax(y_test_oh, axis=1)

print("\nClassification Report (CNN+LSTM):")
print(classification_report(y_true_classes, y_pred_hybrid_classes))
print("Confusion Matrix (CNN+LSTM):")
print(confusion_matrix(y_true_classes, y_pred_hybrid_classes))

"""##Compare CNN vs. LSTM vs. CNN-LSTM Models"""

def plot_comparison(history_cnn, history_lstm, history_hybrid=None):
    """
    Plots training/validation accuracy and loss for up to three models:
    CNN, LSTM, and optional CNN-LSTM (hybrid).

    Parameters:
    - history_cnn:    Keras History object for CNN
    - history_lstm:   Keras History object for LSTM
    - history_hybrid: Keras History object for CNN-LSTM (optional)
    """

    # Extract accuracies/losses for CNN
    acc_cnn = history_cnn.history['accuracy']
    val_acc_cnn = history_cnn.history['val_accuracy']
    loss_cnn = history_cnn.history['loss']
    val_loss_cnn = history_cnn.history['val_loss']
    epochs_cnn = range(1, len(acc_cnn) + 1)

    # Extract accuracies/losses for LSTM
    acc_lstm = history_lstm.history['accuracy']
    val_acc_lstm = history_lstm.history['val_accuracy']
    loss_lstm = history_lstm.history['loss']
    val_loss_lstm = history_lstm.history['val_loss']
    epochs_lstm = range(1, len(acc_lstm) + 1)

    # Optionally extract accuracies/losses for Hybrid (CNN+LSTM)
    if history_hybrid is not None:
        acc_hyb = history_hybrid.history['accuracy']
        val_acc_hyb = history_hybrid.history['val_accuracy']
        loss_hyb = history_hybrid.history['loss']
        val_loss_hyb = history_hybrid.history['val_loss']
        epochs_hyb = range(1, len(acc_hyb) + 1)
    else:
        acc_hyb, val_acc_hyb, loss_hyb, val_loss_hyb, epochs_hyb = None, None, None, None, None

    # -------------------- ACCURACY PLOT --------------------
    plt.figure(figsize=(14, 6))

    plt.subplot(1, 2, 1)  # (rows, cols, index)
    # Plot CNN accuracy
    plt.plot(epochs_cnn, acc_cnn, 'b-o', label='CNN Train Acc')
    plt.plot(epochs_cnn, val_acc_cnn, 'b--o', label='CNN Val Acc')
    # Plot LSTM accuracy
    plt.plot(epochs_lstm, acc_lstm, 'r-s', label='LSTM Train Acc')
    plt.plot(epochs_lstm, val_acc_lstm, 'r--s', label='LSTM Val Acc')
    # Plot Hybrid accuracy if available
    if acc_hyb is not None:
        plt.plot(epochs_hyb, acc_hyb, 'g-^', label='Hybrid Train Acc')
        plt.plot(epochs_hyb, val_acc_hyb, 'g--^', label='Hybrid Val Acc')

    plt.title('Training & Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.7)

    # -------------------- LOSS PLOT --------------------
    plt.subplot(1, 2, 2)
    # Plot CNN loss
    plt.plot(epochs_cnn, loss_cnn, 'b-o', label='CNN Train Loss')
    plt.plot(epochs_cnn, val_loss_cnn, 'b--o', label='CNN Val Loss')
    # Plot LSTM loss
    plt.plot(epochs_lstm, loss_lstm, 'r-s', label='LSTM Train Loss')
    plt.plot(epochs_lstm, val_loss_lstm, 'r--s', label='LSTM Val Loss')
    # Plot Hybrid loss if available
    if loss_hyb is not None:
        plt.plot(epochs_hyb, loss_hyb, 'g-^', label='Hybrid Train Loss')
        plt.plot(epochs_hyb, val_loss_hyb, 'g--^', label='Hybrid Val Loss')

    plt.title('Training & Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.7)

    plt.tight_layout()
    plt.show()

# Now let's show test performance side-by-side in a simple printout/table.

print("===== Test Performance Comparison =====")
print(f"1D CNN ->   Test Loss: {test_loss_cnn:.4f},   Test Accuracy: {test_acc_cnn:.4f}")
print(f"LSTM  ->    Test Loss: {test_loss_lstm:.4f},  Test Accuracy: {test_acc_lstm:.4f}")
print(f"Hybrid ->   Test Loss: {test_loss_hybrid:.4f}, Test Accuracy: {test_acc_hybrid:.4f}")

print("\nSummary Table:")
print("-------------------------------------------------")
print("|  Model    |  Test Loss   |  Test Acc  |")
print("-------------------------------------------------")
print(f"|  CNN      |   {test_loss_cnn:.4f}    |   {test_acc_cnn:.4f}   |")
print(f"|  LSTM     |   {test_loss_lstm:.4f}    |   {test_acc_lstm:.4f}   |")
print(f"|  Hybrid   |   {test_loss_hybrid:.4f}    |   {test_acc_hybrid:.4f}   |")
print("-------------------------------------------------")

# Finally, call the plotting function:
plot_comparison(history_cnn, history_lstm, history_hybrid)