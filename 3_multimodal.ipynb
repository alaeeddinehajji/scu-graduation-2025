{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading data...\n",
      "Normalizing data...\n",
      "Found 378 common samples between EMG and EEG data.\n",
      "Created 19576 windows from 378 samples.\n",
      "Number of classes: 7\n",
      "EMG windows shape: (19576, 50, 8)\n",
      "EEG windows shape: (19576, 50, 8)\n",
      "Epoch 1/30, Train Loss: 1.2394, Train Acc: 52.67%, Val Loss: 0.7855, Val Acc: 74.97%\n",
      "Saved model with accuracy: 74.97%\n",
      "Epoch 2/30, Train Loss: 0.7856, Train Acc: 70.62%, Val Loss: 0.5693, Val Acc: 83.12%\n",
      "Saved model with accuracy: 83.12%\n",
      "Epoch 3/30, Train Loss: 0.6459, Train Acc: 76.80%, Val Loss: 0.4472, Val Acc: 86.87%\n",
      "Saved model with accuracy: 86.87%\n",
      "Epoch 4/30, Train Loss: 0.5508, Train Acc: 80.02%, Val Loss: 0.3651, Val Acc: 89.81%\n",
      "Saved model with accuracy: 89.81%\n",
      "Epoch 5/30, Train Loss: 0.4818, Train Acc: 83.03%, Val Loss: 0.3118, Val Acc: 90.96%\n",
      "Saved model with accuracy: 90.96%\n",
      "Epoch 6/30, Train Loss: 0.4345, Train Acc: 84.74%, Val Loss: 0.2437, Val Acc: 94.41%\n",
      "Saved model with accuracy: 94.41%\n",
      "Epoch 7/30, Train Loss: 0.3887, Train Acc: 86.40%, Val Loss: 0.2107, Val Acc: 94.94%\n",
      "Saved model with accuracy: 94.94%\n",
      "Epoch 8/30, Train Loss: 0.3649, Train Acc: 86.65%, Val Loss: 0.1928, Val Acc: 95.68%\n",
      "Saved model with accuracy: 95.68%\n",
      "Epoch 9/30, Train Loss: 0.3328, Train Acc: 88.40%, Val Loss: 0.1691, Val Acc: 96.09%\n",
      "Saved model with accuracy: 96.09%\n",
      "Epoch 10/30, Train Loss: 0.3162, Train Acc: 89.04%, Val Loss: 0.1398, Val Acc: 97.11%\n",
      "Saved model with accuracy: 97.11%\n",
      "Epoch 11/30, Train Loss: 0.3115, Train Acc: 89.03%, Val Loss: 0.1363, Val Acc: 96.99%\n",
      "Epoch 12/30, Train Loss: 0.2855, Train Acc: 89.85%, Val Loss: 0.1461, Val Acc: 95.76%\n",
      "Epoch 13/30, Train Loss: 0.2744, Train Acc: 90.31%, Val Loss: 0.1019, Val Acc: 97.88%\n",
      "Saved model with accuracy: 97.88%\n",
      "Epoch 14/30, Train Loss: 0.2704, Train Acc: 90.52%, Val Loss: 0.0981, Val Acc: 97.91%\n",
      "Saved model with accuracy: 97.91%\n",
      "Epoch 15/30, Train Loss: 0.2646, Train Acc: 90.84%, Val Loss: 0.1007, Val Acc: 97.57%\n",
      "Epoch 16/30, Train Loss: 0.2443, Train Acc: 91.54%, Val Loss: 0.1081, Val Acc: 96.55%\n",
      "Epoch 17/30, Train Loss: 0.2408, Train Acc: 91.50%, Val Loss: 0.0864, Val Acc: 98.24%\n",
      "Saved model with accuracy: 98.24%\n",
      "Epoch 18/30, Train Loss: 0.2360, Train Acc: 91.65%, Val Loss: 0.0860, Val Acc: 97.96%\n",
      "Epoch 19/30, Train Loss: 0.2238, Train Acc: 92.11%, Val Loss: 0.0871, Val Acc: 97.52%\n",
      "Epoch 20/30, Train Loss: 0.2201, Train Acc: 92.06%, Val Loss: 0.0785, Val Acc: 98.16%\n",
      "Epoch 21/30, Train Loss: 0.2248, Train Acc: 92.32%, Val Loss: 0.0720, Val Acc: 98.37%\n",
      "Saved model with accuracy: 98.37%\n",
      "Epoch 22/30, Train Loss: 0.2064, Train Acc: 92.46%, Val Loss: 0.0669, Val Acc: 98.72%\n",
      "Saved model with accuracy: 98.72%\n",
      "Epoch 23/30, Train Loss: 0.2037, Train Acc: 92.64%, Val Loss: 0.0632, Val Acc: 98.88%\n",
      "Saved model with accuracy: 98.88%\n",
      "Epoch 24/30, Train Loss: 0.1972, Train Acc: 93.26%, Val Loss: 0.0657, Val Acc: 98.49%\n",
      "Epoch 25/30, Train Loss: 0.1967, Train Acc: 93.23%, Val Loss: 0.0634, Val Acc: 98.70%\n",
      "Epoch 26/30, Train Loss: 0.1978, Train Acc: 92.97%, Val Loss: 0.0527, Val Acc: 99.11%\n",
      "Saved model with accuracy: 99.11%\n",
      "Epoch 27/30, Train Loss: 0.1846, Train Acc: 93.41%, Val Loss: 0.0650, Val Acc: 98.24%\n",
      "Epoch 28/30, Train Loss: 0.1859, Train Acc: 93.34%, Val Loss: 0.0566, Val Acc: 98.85%\n",
      "Epoch 29/30, Train Loss: 0.1750, Train Acc: 93.88%, Val Loss: 0.0494, Val Acc: 98.85%\n",
      "Epoch 30/30, Train Loss: 0.1690, Train Acc: 93.97%, Val Loss: 0.0428, Val Acc: 99.36%\n",
      "Saved model with accuracy: 99.36%\n",
      "Training completed!\n",
      "Test Accuracy: 99.36%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "\n",
    "# Set memory optimization flags\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create a custom dataset for multimodal data\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, emg_data, eeg_data, labels):\n",
    "        self.emg_data = torch.FloatTensor(emg_data).to(device)\n",
    "        self.eeg_data = torch.FloatTensor(eeg_data).to(device)\n",
    "        self.labels = torch.LongTensor(labels).to(device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.emg_data[idx], self.eeg_data[idx], self.labels[idx]\n",
    "\n",
    "# Define the EMG encoder network\n",
    "class EMGEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(EMGEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, sequence_length, channels]\n",
    "        x = x.permute(0, 2, 1)  # [batch_size, channels, sequence_length]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        # Global average pooling\n",
    "        x = torch.mean(x, dim=2)\n",
    "        return x\n",
    "\n",
    "# Define the EEG encoder network\n",
    "class EEGEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(EEGEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, sequence_length, channels]\n",
    "        x = x.permute(0, 2, 1)  # [batch_size, channels, sequence_length]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        # Global average pooling\n",
    "        x = torch.mean(x, dim=2)\n",
    "        return x\n",
    "\n",
    "# Define the multimodal fusion network\n",
    "class MultimodalNet(nn.Module):\n",
    "    def __init__(self, emg_input_dim, eeg_input_dim, hidden_dim, window_size, num_classes):\n",
    "        super(MultimodalNet, self).__init__()\n",
    "        \n",
    "        self.emg_encoder = EMGEncoder(emg_input_dim, hidden_dim)\n",
    "        self.eeg_encoder = EEGEncoder(eeg_input_dim, hidden_dim)\n",
    "        \n",
    "        # Fusion layer\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, emg, eeg):\n",
    "        emg_features = self.emg_encoder(emg)\n",
    "        eeg_features = self.eeg_encoder(eeg)\n",
    "        \n",
    "        # Concatenate features\n",
    "        combined = torch.cat((emg_features, eeg_features), dim=1)\n",
    "        \n",
    "        # Pass through fusion layer\n",
    "        output = self.fusion(combined)\n",
    "        return output\n",
    "\n",
    "# Process and load the data\n",
    "def load_and_process_data(emg_path, eeg_path, window_size=50, stride=25):\n",
    "    print(\"Loading data...\")\n",
    "    \n",
    "    # Load data\n",
    "    emg_data = pd.read_csv(emg_path)\n",
    "    eeg_data = pd.read_csv(eeg_path)\n",
    "    \n",
    "    # Extract features and labels\n",
    "    emg_features = emg_data.iloc[:, :8].values\n",
    "    eeg_features = eeg_data.iloc[:, :8].values\n",
    "    \n",
    "    # Standardize the features\n",
    "    print(\"Normalizing data...\")\n",
    "    emg_scaler = StandardScaler()\n",
    "    eeg_scaler = StandardScaler()\n",
    "    \n",
    "    emg_features = emg_scaler.fit_transform(emg_features)\n",
    "    eeg_features = eeg_scaler.fit_transform(eeg_features)\n",
    "    \n",
    "    # Create windowed data\n",
    "    emg_windows = []\n",
    "    eeg_windows = []\n",
    "    window_labels = []\n",
    "    \n",
    "    # Find common samples between EMG and EEG data\n",
    "    emg_samples = set(tuple(x) for x in emg_data[['subject', 'repetition', 'gesture']].drop_duplicates().values)\n",
    "    eeg_samples = set(tuple(x) for x in eeg_data[['subject', 'repetition', 'gesture']].drop_duplicates().values)\n",
    "    common_samples = emg_samples.intersection(eeg_samples)\n",
    "    \n",
    "    print(f\"Found {len(common_samples)} common samples between EMG and EEG data.\")\n",
    "    \n",
    "    for sample in common_samples:\n",
    "        subject, repetition, gesture = sample\n",
    "        \n",
    "        # Get data for this sample\n",
    "        emg_sample = emg_data[(emg_data['subject'] == subject) & \n",
    "                              (emg_data['repetition'] == repetition) & \n",
    "                              (emg_data['gesture'] == gesture)]\n",
    "        \n",
    "        eeg_sample = eeg_data[(eeg_data['subject'] == subject) & \n",
    "                              (eeg_data['repetition'] == repetition) & \n",
    "                              (eeg_data['gesture'] == gesture)]\n",
    "        \n",
    "        # Make sure both samples have data\n",
    "        if len(emg_sample) == 0 or len(eeg_sample) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Extract features\n",
    "        emg_sample_features = emg_sample.iloc[:, :8].values\n",
    "        eeg_sample_features = eeg_sample.iloc[:, :8].values\n",
    "        \n",
    "        # Standardize using pre-fitted scalers\n",
    "        emg_sample_features = emg_scaler.transform(emg_sample_features)\n",
    "        eeg_sample_features = eeg_scaler.transform(eeg_sample_features)\n",
    "        \n",
    "        # Handle different lengths by using the shorter one\n",
    "        min_length = min(len(emg_sample_features), len(eeg_sample_features))\n",
    "        if min_length <= window_size:\n",
    "            continue  # Skip if sample is too short\n",
    "            \n",
    "        emg_sample_features = emg_sample_features[:min_length]\n",
    "        eeg_sample_features = eeg_sample_features[:min_length]\n",
    "        \n",
    "        # Create windows\n",
    "        for i in range(0, min_length - window_size, stride):\n",
    "            emg_windows.append(emg_sample_features[i:i+window_size])\n",
    "            eeg_windows.append(eeg_sample_features[i:i+window_size])\n",
    "            window_labels.append(gesture - 1)  # 0-indexed labels\n",
    "    \n",
    "    if len(emg_windows) == 0:\n",
    "        raise ValueError(\"No valid windows could be created. Check your data alignment.\")\n",
    "    \n",
    "    print(f\"Created {len(emg_windows)} windows from {len(common_samples)} samples.\")\n",
    "    \n",
    "    return np.array(emg_windows), np.array(eeg_windows), np.array(window_labels)\n",
    "\n",
    "# Training function with memory optimizations\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (emg_inputs, eeg_inputs, labels) in enumerate(train_loader):\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(emg_inputs, eeg_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Free up memory\n",
    "            if i % 10 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for emg_inputs, eeg_inputs, labels in val_loader:\n",
    "                outputs = model(emg_inputs, eeg_inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Free memory\n",
    "                del outputs, loss\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100 * correct / total\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_multimodal_model.pth')\n",
    "            print(f'Saved model with accuracy: {val_acc:.2f}%')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    # Hyperparameters\n",
    "    window_size = 50\n",
    "    batch_size = 16  # Smaller batch size to save memory\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 30\n",
    "    hidden_dim = 64  # Reduced hidden dimensions\n",
    "    \n",
    "    # Set paths to your data files\n",
    "    emg_path = 'data/processed/EMG-data.csv'\n",
    "    eeg_path = 'data/processed/EEG-data.csv'\n",
    "    \n",
    "    try:\n",
    "        # Load and process data\n",
    "        emg_windows, eeg_windows, window_labels = load_and_process_data(\n",
    "            emg_path, eeg_path, window_size=window_size\n",
    "        )\n",
    "        \n",
    "        # Calculate number of unique classes\n",
    "        num_classes = len(np.unique(window_labels))\n",
    "        print(f\"Number of classes: {num_classes}\")\n",
    "        print(f\"EMG windows shape: {emg_windows.shape}\")\n",
    "        print(f\"EEG windows shape: {eeg_windows.shape}\")\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_emg_train, X_emg_test, X_eeg_train, X_eeg_test, y_train, y_test = train_test_split(\n",
    "            emg_windows, eeg_windows, window_labels, test_size=0.2, random_state=42, stratify=window_labels\n",
    "        )\n",
    "        \n",
    "        # Free up memory\n",
    "        del emg_windows, eeg_windows, window_labels\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = MultimodalDataset(X_emg_train, X_eeg_train, y_train)\n",
    "        test_dataset = MultimodalDataset(X_emg_test, X_eeg_test, y_test)\n",
    "        \n",
    "        # Free up more memory\n",
    "        del X_emg_train, X_emg_test, X_eeg_train, X_eeg_test, y_train, y_test\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Create data loaders with smaller batch sizes\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True, \n",
    "            pin_memory=False  # Disable pin_memory to save RAM\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=batch_size, shuffle=False,\n",
    "            pin_memory=False\n",
    "        )\n",
    "        \n",
    "        # Initialize model\n",
    "        emg_input_dim = 8  # Number of EMG channels\n",
    "        eeg_input_dim = 8  # Number of EEG channels\n",
    "        \n",
    "        model = MultimodalNet(\n",
    "            emg_input_dim=emg_input_dim,\n",
    "            eeg_input_dim=eeg_input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            window_size=window_size,\n",
    "            num_classes=num_classes\n",
    "        ).to(device)\n",
    "        \n",
    "        # Define optimizer and loss function\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "        \n",
    "        # Train the model\n",
    "        trained_model = train_model(\n",
    "            model, train_loader, test_loader, criterion, optimizer, num_epochs=num_epochs\n",
    "        )\n",
    "        \n",
    "        print(\"Training completed!\")\n",
    "        \n",
    "        # Evaluate the model\n",
    "        trained_model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for emg_inputs, eeg_inputs, labels in test_loader:\n",
    "                outputs = trained_model(emg_inputs, eeg_inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        print(\"\\nAlternative approach: Let's try with paired data synchronization...\")\n",
    "        # If the first method fails, you could implement an alternative approach here\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading data...\n",
      "Normalizing data...\n",
      "Found 378 common samples between EMG and EEG data.\n",
      "Created 19576 windows from 378 samples.\n",
      "Number of classes: 7\n",
      "EMG windows shape: (19576, 50, 8)\n",
      "EEG windows shape: (19576, 50, 8)\n",
      "Training set: 11752 samples\n",
      "Validation set: 3900 samples\n",
      "Test set: 3924 samples\n",
      "Model has 318,343 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\work\\AppData\\Local\\Temp\\ipykernel_5380\\2281970095.py:257: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "C:\\Users\\work\\AppData\\Local\\Temp\\ipykernel_5380\\2281970095.py:285: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 1.0230, Train Acc: 62.89%, Train F1: 0.6263, Val Loss: 0.9969, Val Acc: 62.03%, Val F1: 0.6154\n",
      "Precision: 0.7088, Recall: 0.6203\n",
      "Saved model with F1: 0.6154, Accuracy: 62.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\work\\AppData\\Local\\Temp\\ipykernel_5380\\2281970095.py:285: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.5979, Train Acc: 79.34%, Train F1: 0.7923, Val Loss: 0.8132, Val Acc: 71.31%, Val F1: 0.7050\n",
      "Precision: 0.7710, Recall: 0.7131\n",
      "Saved model with F1: 0.7050, Accuracy: 71.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\work\\AppData\\Local\\Temp\\ipykernel_5380\\2281970095.py:285: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.4315, Train Acc: 85.37%, Train F1: 0.8529, Val Loss: 0.6387, Val Acc: 78.49%, Val F1: 0.7772\n",
      "Precision: 0.8228, Recall: 0.7849\n",
      "Saved model with F1: 0.7772, Accuracy: 78.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\work\\AppData\\Local\\Temp\\ipykernel_5380\\2281970095.py:285: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.3464, Train Acc: 88.43%, Train F1: 0.8838, Val Loss: 0.6332, Val Acc: 80.56%, Val F1: 0.7947\n",
      "Precision: 0.8358, Recall: 0.8056\n",
      "Saved model with F1: 0.7947, Accuracy: 80.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\work\\AppData\\Local\\Temp\\ipykernel_5380\\2281970095.py:285: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.2982, Train Acc: 89.80%, Train F1: 0.8975, Val Loss: 0.5737, Val Acc: 82.64%, Val F1: 0.8220\n",
      "Precision: 0.8604, Recall: 0.8264\n",
      "Saved model with F1: 0.8220, Accuracy: 82.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\work\\AppData\\Local\\Temp\\ipykernel_5380\\2281970095.py:285: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.2594, Train Acc: 91.36%, Train F1: 0.9132, Val Loss: 0.5448, Val Acc: 83.10%, Val F1: 0.8291\n",
      "Precision: 0.8527, Recall: 0.8310\n",
      "Saved model with F1: 0.8291, Accuracy: 83.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\work\\AppData\\Local\\Temp\\ipykernel_5380\\2281970095.py:285: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.2304, Train Acc: 92.07%, Train F1: 0.9204, Val Loss: 0.5196, Val Acc: 83.64%, Val F1: 0.8316\n",
      "Precision: 0.8619, Recall: 0.8364\n",
      "Saved model with F1: 0.8316, Accuracy: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\work\\AppData\\Local\\Temp\\ipykernel_5380\\2281970095.py:285: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 581\u001b[39m\n\u001b[32m    579\u001b[39m         traceback.print_exc()\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 534\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    531\u001b[39m scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=learning_rate/\u001b[32m100\u001b[39m)\n\u001b[32m    533\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m trained_model, history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining completed!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    540\u001b[39m \u001b[38;5;66;03m# WORKAROUND: Skip loading the saved checkpoint and use the just-trained model instead\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 274\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs)\u001b[39m\n\u001b[32m    270\u001b[39m all_targets = []\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (emg_inputs, eeg_inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[32m    273\u001b[39m     \u001b[38;5;66;03m# Move data to device\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m     emg_inputs, eeg_inputs, labels = \u001b[43memg_inputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, eeg_inputs.to(device), labels.to(device)\n\u001b[32m    276\u001b[39m     \u001b[38;5;66;03m# Data augmentation (add noise) in training only\u001b[39;00m\n\u001b[32m    277\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m random.random() < \u001b[32m0.5\u001b[39m:  \u001b[38;5;66;03m# 50% chance to apply noise\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.amp import autocast, GradScaler\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "import random\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# Set memory optimization flags and reproducibility\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.empty_cache()\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create a custom dataset for multimodal data - Fixed to load data to GPU only when needed\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, emg_data, eeg_data, labels):\n",
    "        self.emg_data = torch.FloatTensor(emg_data)\n",
    "        self.eeg_data = torch.FloatTensor(eeg_data)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.emg_data[idx], self.eeg_data[idx], self.labels[idx]\n",
    "\n",
    "# Define the improved EMG encoder network\n",
    "class EMGEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(EMGEncoder, self).__init__()\n",
    "        # Deeper architecture with multiple convolutional layers\n",
    "        self.conv1 = nn.Conv1d(input_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim*2, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim*2)\n",
    "        self.conv3 = nn.Conv1d(hidden_dim*2, hidden_dim*2, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim*2)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, sequence_length, channels]\n",
    "        x = x.permute(0, 2, 1)  # [batch_size, channels, sequence_length]\n",
    "        \n",
    "        # First convolutional block\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Third convolutional block\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Both global average pooling and max pooling for better feature extraction\n",
    "        avg_pool = torch.mean(x, dim=2)\n",
    "        max_pool, _ = torch.max(x, dim=2)\n",
    "        \n",
    "        # Concatenate both pooling results\n",
    "        x = torch.cat([avg_pool, max_pool], dim=1)\n",
    "        return x\n",
    "\n",
    "# Define the improved EEG encoder network\n",
    "class EEGEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(EEGEncoder, self).__init__()\n",
    "        # Deeper architecture with multiple convolutional layers\n",
    "        self.conv1 = nn.Conv1d(input_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim*2, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim*2)\n",
    "        self.conv3 = nn.Conv1d(hidden_dim*2, hidden_dim*2, kernel_size=3, padding=1) \n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim*2)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, sequence_length, channels]\n",
    "        x = x.permute(0, 2, 1)  # [batch_size, channels, sequence_length]\n",
    "        \n",
    "        # First convolutional block\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Third convolutional block\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Both global average pooling and max pooling for better feature extraction\n",
    "        avg_pool = torch.mean(x, dim=2)\n",
    "        max_pool, _ = torch.max(x, dim=2)\n",
    "        \n",
    "        # Concatenate both pooling results\n",
    "        x = torch.cat([avg_pool, max_pool], dim=1)\n",
    "        return x\n",
    "\n",
    "# Define the improved multimodal fusion network\n",
    "class MultimodalNet(nn.Module):\n",
    "    def __init__(self, emg_input_dim, eeg_input_dim, hidden_dim, num_classes):\n",
    "        super(MultimodalNet, self).__init__()\n",
    "        \n",
    "        self.emg_encoder = EMGEncoder(emg_input_dim, hidden_dim)\n",
    "        self.eeg_encoder = EEGEncoder(eeg_input_dim, hidden_dim)\n",
    "        \n",
    "        # Calculate the size of concatenated features (doubled due to dual pooling)\n",
    "        concat_size = hidden_dim * 2 * 2 * 2  # 2 encoders x 2 feature sizes each x 2 pooling types\n",
    "        \n",
    "        # Improved fusion layer with additional layers\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(concat_size, hidden_dim * 4),\n",
    "            nn.BatchNorm1d(hidden_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim * 2),\n",
    "            nn.BatchNorm1d(hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim * 2, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, emg, eeg):\n",
    "        emg_features = self.emg_encoder(emg)\n",
    "        eeg_features = self.eeg_encoder(eeg)\n",
    "        \n",
    "        # Concatenate features\n",
    "        combined = torch.cat((emg_features, eeg_features), dim=1)\n",
    "        \n",
    "        # Pass through fusion layer\n",
    "        output = self.fusion(combined)\n",
    "        return output\n",
    "\n",
    "# Add noise to data for augmentation\n",
    "def add_noise(data, noise_factor=0.05):\n",
    "    noise = torch.randn(data.shape).to(data.device) * noise_factor * torch.std(data)\n",
    "    return data + noise\n",
    "\n",
    "# Process and load the data\n",
    "def load_and_process_data(emg_path, eeg_path, window_size=50, stride=25):\n",
    "    print(\"Loading data...\")\n",
    "    \n",
    "    # Load data\n",
    "    emg_data = pd.read_csv(emg_path)\n",
    "    eeg_data = pd.read_csv(eeg_path)\n",
    "    \n",
    "    # Extract features and labels\n",
    "    emg_features = emg_data.iloc[:, :8].values\n",
    "    eeg_features = eeg_data.iloc[:, :8].values\n",
    "    \n",
    "    # Standardize the features\n",
    "    print(\"Normalizing data...\")\n",
    "    emg_scaler = StandardScaler()\n",
    "    eeg_scaler = StandardScaler()\n",
    "    \n",
    "    emg_features = emg_scaler.fit_transform(emg_features)\n",
    "    eeg_features = eeg_scaler.fit_transform(eeg_features)\n",
    "    \n",
    "    # Create windowed data\n",
    "    emg_windows = []\n",
    "    eeg_windows = []\n",
    "    window_labels = []\n",
    "    sample_ids = []  # Track sample IDs for stratified splits\n",
    "    \n",
    "    # Find common samples between EMG and EEG data\n",
    "    emg_samples = set(tuple(x) for x in emg_data[['subject', 'repetition', 'gesture']].drop_duplicates().values)\n",
    "    eeg_samples = set(tuple(x) for x in eeg_data[['subject', 'repetition', 'gesture']].drop_duplicates().values)\n",
    "    common_samples = emg_samples.intersection(eeg_samples)\n",
    "    \n",
    "    print(f\"Found {len(common_samples)} common samples between EMG and EEG data.\")\n",
    "    \n",
    "    for sample in common_samples:\n",
    "        subject, repetition, gesture = sample\n",
    "        \n",
    "        # Get data for this sample\n",
    "        emg_sample = emg_data[(emg_data['subject'] == subject) & \n",
    "                              (emg_data['repetition'] == repetition) & \n",
    "                              (emg_data['gesture'] == gesture)]\n",
    "        \n",
    "        eeg_sample = eeg_data[(eeg_data['subject'] == subject) & \n",
    "                              (eeg_data['repetition'] == repetition) & \n",
    "                              (eeg_data['gesture'] == gesture)]\n",
    "        \n",
    "        # Make sure both samples have data\n",
    "        if len(emg_sample) == 0 or len(eeg_sample) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Extract features\n",
    "        emg_sample_features = emg_sample.iloc[:, :8].values\n",
    "        eeg_sample_features = eeg_sample.iloc[:, :8].values\n",
    "        \n",
    "        # Standardize using pre-fitted scalers\n",
    "        emg_sample_features = emg_scaler.transform(emg_sample_features)\n",
    "        eeg_sample_features = eeg_scaler.transform(eeg_sample_features)\n",
    "        \n",
    "        # Handle different lengths by using the shorter one\n",
    "        min_length = min(len(emg_sample_features), len(eeg_sample_features))\n",
    "        if min_length <= window_size:\n",
    "            continue  # Skip if sample is too short\n",
    "            \n",
    "        emg_sample_features = emg_sample_features[:min_length]\n",
    "        eeg_sample_features = eeg_sample_features[:min_length]\n",
    "        \n",
    "        # Create windows\n",
    "        for i in range(0, min_length - window_size, stride):\n",
    "            emg_windows.append(emg_sample_features[i:i+window_size])\n",
    "            eeg_windows.append(eeg_sample_features[i:i+window_size])\n",
    "            window_labels.append(gesture - 1)  # 0-indexed labels\n",
    "            sample_ids.append(f\"{subject}_{repetition}_{gesture}\")  # Track which sample this comes from\n",
    "    \n",
    "    if len(emg_windows) == 0:\n",
    "        raise ValueError(\"No valid windows could be created. Check your data alignment.\")\n",
    "    \n",
    "    print(f\"Created {len(emg_windows)} windows from {len(common_samples)} samples.\")\n",
    "    \n",
    "    return np.array(emg_windows), np.array(eeg_windows), np.array(window_labels), np.array(sample_ids)\n",
    "\n",
    "# Training function with memory optimizations, mixed precision, and metrics tracking\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    best_acc = 0.0\n",
    "    best_f1 = 0.0\n",
    "    \n",
    "    # Initialize gradient scaler for mixed precision training - FIXED\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Keep track of metrics\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [], 'train_f1': [],\n",
    "        'val_loss': [], 'val_acc': [], 'val_f1': [],\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        for i, (emg_inputs, eeg_inputs, labels) in enumerate(train_loader):\n",
    "            # Move data to device\n",
    "            emg_inputs, eeg_inputs, labels = emg_inputs.to(device), eeg_inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Data augmentation (add noise) in training only\n",
    "            if random.random() < 0.5:  # 50% chance to apply noise\n",
    "                emg_inputs = add_noise(emg_inputs, noise_factor=0.03)\n",
    "                eeg_inputs = add_noise(eeg_inputs, noise_factor=0.03)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with mixed precision - FIXED\n",
    "            with autocast():\n",
    "                outputs = model(emg_inputs, eeg_inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize with gradient scaling\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Store predictions and labels for F1 score calculation\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Free up memory\n",
    "            if i % 10 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * np.mean(np.array(all_preds) == np.array(all_targets))\n",
    "        train_f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "        \n",
    "        # Rest of the function remains the same...\n",
    "               \n",
    "        # Store metrics\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_f1'].append(train_f1)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for emg_inputs, eeg_inputs, labels in val_loader:\n",
    "                # Move data to device\n",
    "                emg_inputs, eeg_inputs, labels = emg_inputs.to(device), eeg_inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass (no mixed precision needed for validation)\n",
    "                outputs = model(emg_inputs, eeg_inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Store predictions and labels\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_targets.extend(labels.cpu().numpy())\n",
    "                \n",
    "                # Free memory\n",
    "                del outputs, loss\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100 * np.mean(np.array(all_preds) == np.array(all_targets))\n",
    "        val_f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "        val_precision = precision_score(all_targets, all_preds, average='weighted')\n",
    "        val_recall = recall_score(all_targets, all_preds, average='weighted')\n",
    "        \n",
    "        # Store metrics\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Train F1: {train_f1:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, Val F1: {val_f1:.4f}')\n",
    "        print(f'Precision: {val_precision:.4f}, Recall: {val_recall:.4f}')\n",
    "        \n",
    "        # Save the best model based on F1 score (more informative than accuracy)\n",
    "        # In the train_model function, update the model saving part:\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_acc = val_acc\n",
    "            # Save only the necessary components\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'val_f1': val_f1,\n",
    "                'val_acc': val_acc,\n",
    "            }, 'best_multimodal_model.pth')\n",
    "            # Save history separately if needed\n",
    "            np.save('training_history.npy', history)\n",
    "            print(f'Saved model with F1: {val_f1:.4f}, Accuracy: {val_acc:.2f}%')\n",
    "    \n",
    "    return model, history\n",
    "# Function to evaluate on test set\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for emg_inputs, eeg_inputs, labels in test_loader:\n",
    "            # Move data to device\n",
    "            emg_inputs, eeg_inputs, labels = emg_inputs.to(device), eeg_inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(emg_inputs, eeg_inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Store predictions and labels\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = 100 * np.mean(np.array(all_preds) == np.array(all_targets))\n",
    "    f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "    precision = precision_score(all_targets, all_preds, average='weighted')\n",
    "    recall = recall_score(all_targets, all_preds, average='weighted')\n",
    "    conf_matrix = confusion_matrix(all_targets, all_preds)\n",
    "    \n",
    "    print(\"Test Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # Make sure numpy is imported inside the function \n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import gc\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Hyperparameters\n",
    "    window_size = 50\n",
    "    batch_size = 32  # Adjusted batch size for mixed precision\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 30\n",
    "    hidden_dim = 64\n",
    "    \n",
    "    # Set paths to your data files\n",
    "    emg_path = 'data/processed/EMG-data.csv'\n",
    "    eeg_path = 'data/processed/EEG-data.csv'\n",
    "    \n",
    "    try:\n",
    "        # Load and process data\n",
    "        emg_windows, eeg_windows, window_labels, sample_ids = load_and_process_data(\n",
    "            emg_path, eeg_path, window_size=window_size\n",
    "        )\n",
    "        \n",
    "        # Calculate number of unique classes\n",
    "        num_classes = len(np.unique(window_labels))\n",
    "        print(f\"Number of classes: {num_classes}\")\n",
    "        print(f\"EMG windows shape: {emg_windows.shape}\")\n",
    "        print(f\"EEG windows shape: {eeg_windows.shape}\")\n",
    "        \n",
    "        # New: Proper train/val/test split (60/20/20) - stratified by sample_id to prevent data leakage\n",
    "        # First, get unique sample_ids\n",
    "        unique_samples = np.unique(sample_ids)\n",
    "        \n",
    "        # Use sklearn's train_test_split to split the sample IDs\n",
    "        samples_train, samples_temp = train_test_split(\n",
    "            unique_samples, test_size=0.4, random_state=42\n",
    "        )\n",
    "        samples_val, samples_test = train_test_split(\n",
    "            samples_temp, test_size=0.5, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Now create masks based on these sample IDs\n",
    "        train_mask = np.isin(sample_ids, samples_train)\n",
    "        val_mask = np.isin(sample_ids, samples_val)\n",
    "        test_mask = np.isin(sample_ids, samples_test)\n",
    "        \n",
    "        # Apply masks to get the actual data splits\n",
    "        X_emg_train, X_eeg_train, y_train = emg_windows[train_mask], eeg_windows[train_mask], window_labels[train_mask]\n",
    "        X_emg_val, X_eeg_val, y_val = emg_windows[val_mask], eeg_windows[val_mask], window_labels[val_mask]\n",
    "        X_emg_test, X_eeg_test, y_test = emg_windows[test_mask], eeg_windows[test_mask], window_labels[test_mask]\n",
    "        \n",
    "        print(f\"Training set: {len(X_emg_train)} samples\")\n",
    "        print(f\"Validation set: {len(X_emg_val)} samples\")\n",
    "        print(f\"Test set: {len(X_emg_test)} samples\")\n",
    "        \n",
    "        # Free up memory\n",
    "        del emg_windows, eeg_windows, window_labels, sample_ids\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = MultimodalDataset(X_emg_train, X_eeg_train, y_train)\n",
    "        val_dataset = MultimodalDataset(X_emg_val, X_eeg_val, y_val)\n",
    "        test_dataset = MultimodalDataset(X_emg_test, X_eeg_test, y_test)\n",
    "        \n",
    "        # Free up more memory\n",
    "        del X_emg_train, X_emg_val, X_emg_test, X_eeg_train, X_eeg_val, X_eeg_test, y_train, y_val, y_test\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Create data loaders with modified parameters\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True, \n",
    "            pin_memory=True, num_workers=0  # Changed from 2 to 0\n",
    "        )\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, batch_size=batch_size, shuffle=False,\n",
    "            pin_memory=True, num_workers=0  # Changed from 2 to 0\n",
    "        )\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, batch_size=batch_size, shuffle=False,\n",
    "            pin_memory=True, num_workers=0  # Changed from 2 to 0\n",
    "        )\n",
    "\n",
    "        # Initialize model\n",
    "        emg_input_dim = 8  # Number of EMG channels\n",
    "        eeg_input_dim = 8  # Number of EEG channels\n",
    "        \n",
    "        model = MultimodalNet(\n",
    "            emg_input_dim=emg_input_dim,\n",
    "            eeg_input_dim=eeg_input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_classes=num_classes\n",
    "        ).to(device)\n",
    "        \n",
    "        # Count parameters\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"Model has {total_params:,} parameters\")\n",
    "        \n",
    "        # Define optimizer and loss function\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "        \n",
    "        # Define cosine annealing learning rate scheduler\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=learning_rate/100)\n",
    "        \n",
    "        # Train the model\n",
    "        trained_model, history = train_model(\n",
    "            model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=num_epochs\n",
    "        )\n",
    "        \n",
    "        print(\"Training completed!\")\n",
    "        \n",
    "        # WORKAROUND: Skip loading the saved checkpoint and use the just-trained model instead\n",
    "        print(\"Checkpoint loading failed - using the most recently trained model instead.\")\n",
    "        \n",
    "        # Use the metrics from the last epoch of training\n",
    "        if history and 'val_f1' in history and len(history['val_f1']) > 0:\n",
    "            best_epoch = num_epochs - 1  # Last epoch\n",
    "            best_val_f1 = history['val_f1'][-1]\n",
    "            best_val_acc = history['val_acc'][-1]\n",
    "            \n",
    "            print(f\"Using model from final epoch {best_epoch+1} with validation F1: {best_val_f1:.4f}, \"\n",
    "                  f\"validation accuracy: {best_val_acc:.2f}%\")\n",
    "        else:\n",
    "            # Fallback if history isn't available\n",
    "            best_epoch = num_epochs - 1\n",
    "            best_val_f1 = 0.0\n",
    "            best_val_acc = 0.0\n",
    "            print(\"Using model from final epoch (metrics not available)\")\n",
    "        \n",
    "        # Evaluate the model on test set\n",
    "        test_results = evaluate_model(model, test_loader)\n",
    "        \n",
    "        print(f\"Test F1 Score: {test_results['f1']:.4f}\")\n",
    "        print(f\"Test Accuracy: {test_results['accuracy']:.2f}%\")\n",
    "        \n",
    "        # Save final results\n",
    "        final_results = {\n",
    "            'best_epoch': best_epoch,\n",
    "            'best_val_f1': best_val_f1,\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'test_results': test_results,\n",
    "            'history': history\n",
    "        }\n",
    "        \n",
    "        # Save as numpy file for later analysis\n",
    "        np.save('model_results.npy', final_results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
