{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading data...\n",
      "Converting data types...\n",
      "Normalizing data...\n",
      "üü¢ EMG Sample Info:\n",
      "üìè Length: 664666, üõ†Ô∏è Shape: (664666, 11)\n",
      "   Channel_1  Channel_2  Channel_3  Channel_4  Channel_5  Channel_6  \\\n",
      "0  -0.144347  -0.463070  -1.254146  -0.539958   0.018249   0.174389   \n",
      "1   0.192552   0.661711   0.213725   0.350381   0.099978   0.106335   \n",
      "2   1.708598   1.395264   0.847578   0.680136  -1.820643  -0.846416   \n",
      "3  -1.772693  -1.294429  -0.253325   1.504524   2.633563   0.991033   \n",
      "4   2.270097  -1.685657  -1.621114   0.779063   0.386028   0.106335   \n",
      "\n",
      "   Channel_7  Channel_8  subject  repetition  gesture  \n",
      "0  -0.026852   0.020317        1           1        1  \n",
      "1  -0.723067  -0.825154        1           1        1  \n",
      "2  -1.013157   0.999284        1           1        1  \n",
      "3   1.191525   0.732293        1           1        1  \n",
      "4  -0.897121  -0.068680        1           1        1  \n",
      "üìä EMG Data Types:\n",
      "Channel_1     float64\n",
      "Channel_2     float64\n",
      "Channel_3     float64\n",
      "Channel_4     float64\n",
      "Channel_5     float64\n",
      "Channel_6     float64\n",
      "Channel_7     float64\n",
      "Channel_8     float64\n",
      "subject         int64\n",
      "repetition      int64\n",
      "gesture         int64\n",
      "dtype: object\n",
      "\n",
      "üü£ EEG Sample Info:\n",
      "üìè Length: 564641, üõ†Ô∏è Shape: (564641, 11)\n",
      "   Channel_1  Channel_2  Channel_3  Channel_4  Channel_5  Channel_6  \\\n",
      "0  -0.682722   0.396471   0.611564   0.395874  -0.934352  -0.020220   \n",
      "1  -0.676323   0.376561   0.619530   0.398924  -0.936023  -0.019176   \n",
      "2  -0.669394   0.479082   0.672759   0.398901  -0.945381  -0.025628   \n",
      "3  -0.674662   0.513458   0.672159   0.395938  -0.945159  -0.027701   \n",
      "4  -0.682106   0.414412   0.618319   0.395602  -0.935618  -0.021366   \n",
      "\n",
      "   Channel_7  Channel_8  subject  repetition  gesture  \n",
      "0   0.772740   0.360400        1           1        1  \n",
      "1   0.771758   0.360254        1           1        1  \n",
      "2   0.761913   0.351775        1           1        1  \n",
      "3   0.761492   0.350618        1           1        1  \n",
      "4   0.771463   0.358991        1           1        1  \n",
      "üìä EEG Data Types:\n",
      "Channel_1     float64\n",
      "Channel_2     float64\n",
      "Channel_3     float64\n",
      "Channel_4     float64\n",
      "Channel_5     float64\n",
      "Channel_6     float64\n",
      "Channel_7     float64\n",
      "Channel_8     float64\n",
      "subject         int64\n",
      "repetition      int64\n",
      "gesture         int64\n",
      "dtype: object\n",
      "Creating EMGEEGDataset...\n",
      "Found 378 common sample keys\n",
      "Processed 100 samples\n",
      "Processed 200 samples\n",
      "Processed 300 samples\n",
      "Successfully created dataset with 377 samples\n",
      "Dataset splits: Train 263, Validation 56, Test 58\n",
      "Number of classes: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training:   0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Memory-efficient implementation\n",
    "class EMGEEGDataset(Dataset):\n",
    "    def __init__(self, emg_data, eeg_data, transform=None):\n",
    "        print(\"Creating EMGEEGDataset...\")\n",
    "        # Fixed window size for all samples\n",
    "        self.window_size = 1000\n",
    "        \n",
    "        # Filter to have matching samples (subject, repetition, gesture)\n",
    "        emg_keys = emg_data[['subject', 'repetition', 'gesture']].apply(tuple, axis=1)\n",
    "        eeg_keys = eeg_data[['subject', 'repetition', 'gesture']].apply(tuple, axis=1)\n",
    "        \n",
    "        # Find common keys\n",
    "        common_keys = set(emg_keys).intersection(set(eeg_keys))\n",
    "        print(f\"Found {len(common_keys)} common sample keys\")\n",
    "        \n",
    "        # Filter data to include only common keys\n",
    "        self.emg_samples = []\n",
    "        self.eeg_samples = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Track processed samples\n",
    "        processed = 0\n",
    "        \n",
    "        for subject, repetition, gesture in common_keys:\n",
    "            # Get EMG data for this key\n",
    "            emg_sample = emg_data[(emg_data['subject'] == subject) & \n",
    "                                  (emg_data['repetition'] == repetition) & \n",
    "                                  (emg_data['gesture'] == gesture)]\n",
    "            \n",
    "            # Get EEG data for this key\n",
    "            eeg_sample = eeg_data[(eeg_data['subject'] == subject) & \n",
    "                                  (eeg_data['repetition'] == repetition) & \n",
    "                                  (eeg_data['gesture'] == gesture)]\n",
    "            \n",
    "            # Skip if insufficient data\n",
    "            if len(emg_sample) < 10 or len(eeg_sample) < 10:\n",
    "                continue\n",
    "            \n",
    "            # Get features (first 8 columns are channel data)\n",
    "            emg_features = emg_sample.iloc[:, :8].values\n",
    "            eeg_features = eeg_sample.iloc[:, :8].values\n",
    "            \n",
    "            # Make sure features are the expected type\n",
    "            emg_features = emg_features.astype(np.float32)\n",
    "            eeg_features = eeg_features.astype(np.float32)\n",
    "            \n",
    "            # Use the fixed window size\n",
    "            window_size = self.window_size\n",
    "            \n",
    "            # Truncate or pad as necessary\n",
    "            if len(emg_features) > window_size:\n",
    "                emg_features = emg_features[:window_size]\n",
    "            else:\n",
    "                # Pad with zeros\n",
    "                pad_length = window_size - len(emg_features)\n",
    "                emg_features = np.vstack([emg_features, np.zeros((pad_length, 8), dtype=np.float32)])\n",
    "            \n",
    "            if len(eeg_features) > window_size:\n",
    "                eeg_features = eeg_features[:window_size]\n",
    "            else:\n",
    "                # Pad with zeros\n",
    "                pad_length = window_size - len(eeg_features)\n",
    "                eeg_features = np.vstack([eeg_features, np.zeros((pad_length, 8), dtype=np.float32)])\n",
    "            \n",
    "            # Append to lists\n",
    "            self.emg_samples.append(emg_features)\n",
    "            self.eeg_samples.append(eeg_features)\n",
    "            self.labels.append(gesture - 1)  # Adjust to 0-indexed\n",
    "            \n",
    "            processed += 1\n",
    "            if processed % 100 == 0:\n",
    "                print(f\"Processed {processed} samples\")\n",
    "        \n",
    "        print(f\"Successfully created dataset with {len(self.labels)} samples\")\n",
    "        \n",
    "        # Keep as lists instead of converting to numpy arrays (to handle variable lengths)\n",
    "        self.labels = np.array(self.labels)\n",
    "        \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        emg_sample = self.emg_samples[idx]\n",
    "        eeg_sample = self.eeg_samples[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            emg_sample = self.transform(emg_sample)\n",
    "            eeg_sample = self.transform(eeg_sample)\n",
    "        \n",
    "        # Convert to torch tensors (ensure numpy array first)\n",
    "        emg_tensor = torch.tensor(emg_sample, dtype=torch.float)\n",
    "        eeg_tensor = torch.tensor(eeg_sample, dtype=torch.float)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return emg_tensor, eeg_tensor, label_tensor\n",
    "\n",
    "# Memory-efficient data loading function\n",
    "def load_and_preprocess_data(emg_path, eeg_path):\n",
    "    print(\"Loading data...\")\n",
    "    \n",
    "    # Load data\n",
    "    emg_data = pd.read_csv(emg_path)\n",
    "    eeg_data = pd.read_csv(eeg_path)\n",
    "    \n",
    "    print(\"Converting data types...\")\n",
    "    # Convert channel columns to float64 first to avoid FutureWarning\n",
    "    for col in emg_data.columns[:8]:\n",
    "        emg_data[col] = emg_data[col].astype('float64')\n",
    "    \n",
    "    for col in eeg_data.columns[:8]:\n",
    "        eeg_data[col] = eeg_data[col].astype('float64')\n",
    "    \n",
    "    print(\"Normalizing data...\")\n",
    "    \n",
    "    # Normalize channel data (first 8 columns)\n",
    "    emg_scaler = StandardScaler()\n",
    "    eeg_scaler = StandardScaler()\n",
    "    \n",
    "    # Scale only channel columns (first 8)\n",
    "    emg_data.iloc[:, :8] = emg_scaler.fit_transform(emg_data.iloc[:, :8])\n",
    "    eeg_data.iloc[:, :8] = eeg_scaler.fit_transform(eeg_data.iloc[:, :8])\n",
    "    \n",
    "    # Print info about the data\n",
    "    print(\"üü¢ EMG Sample Info:\")\n",
    "    print(f\"üìè Length: {len(emg_data)}, üõ†Ô∏è Shape: {emg_data.shape}\")\n",
    "    print(emg_data.head())\n",
    "    print(\"üìä EMG Data Types:\")\n",
    "    print(emg_data.dtypes)\n",
    "    \n",
    "    print(\"\\nüü£ EEG Sample Info:\")\n",
    "    print(f\"üìè Length: {len(eeg_data)}, üõ†Ô∏è Shape: {eeg_data.shape}\")\n",
    "    print(eeg_data.head())\n",
    "    print(\"üìä EEG Data Types:\")\n",
    "    print(eeg_data.dtypes)\n",
    "    \n",
    "    return emg_data, eeg_data\n",
    "\n",
    "# CNN Model\n",
    "class MultimodalCNN(nn.Module):\n",
    "    def __init__(self, num_classes=7, window_size=1000):\n",
    "        super(MultimodalCNN, self).__init__()\n",
    "        \n",
    "        # EMG branch\n",
    "        self.emg_conv = nn.Sequential(\n",
    "            nn.Conv1d(8, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # EEG branch\n",
    "        self.eeg_conv = nn.Sequential(\n",
    "            nn.Conv1d(8, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Fusion and classification layers\n",
    "        # Calculate feature size after convolutions and pooling\n",
    "        # After 3 max pooling layers (each dividing by 2), the feature size is window_size / 2^3\n",
    "        feature_length = window_size // 8  # window_size divided by 2^3\n",
    "        self.feature_size = 128 * feature_length\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.feature_size * 2, 512),  # *2 because we concatenate EMG and EEG features\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, emg, eeg):\n",
    "        # Transpose to get channels as first dimension for Conv1d (batch, channels, sequence)\n",
    "        emg = emg.permute(0, 2, 1)\n",
    "        eeg = eeg.permute(0, 2, 1)\n",
    "        \n",
    "        # Print shapes for debugging\n",
    "        # print(f\"EMG input shape: {emg.shape}\")\n",
    "        # print(f\"EEG input shape: {eeg.shape}\")\n",
    "        \n",
    "        # EMG branch\n",
    "        emg_features = self.emg_conv(emg)\n",
    "        # print(f\"EMG features shape: {emg_features.shape}\")\n",
    "        emg_features = emg_features.reshape(emg_features.size(0), -1)  # Flatten\n",
    "        \n",
    "        # EEG branch\n",
    "        eeg_features = self.eeg_conv(eeg)\n",
    "        # print(f\"EEG features shape: {eeg_features.shape}\")\n",
    "        eeg_features = eeg_features.reshape(eeg_features.size(0), -1)  # Flatten\n",
    "        \n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat((emg_features, eeg_features), dim=1)\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(combined_features)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Training and evaluation function\n",
    "def train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, num_epochs=50, patience=10):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for emg_data, eeg_data, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "            emg_data, eeg_data, labels = emg_data.to(device), eeg_data.to(device), labels.to(device)\n",
    "            \n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(emg_data, eeg_data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Free up memory\n",
    "            del emg_data, eeg_data, labels, outputs\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for emg_data, eeg_data, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "                emg_data, eeg_data, labels = emg_data.to(device), eeg_data.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(emg_data, eeg_data)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Update statistics\n",
    "                val_running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Free up memory\n",
    "                del emg_data, eeg_data, labels, outputs\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        val_loss = val_running_loss / len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        # Print statistics\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        # Garbage collection\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Plot training and validation loss/accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Train Acc')\n",
    "    plt.plot(val_accs, label='Val Acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Paths to EMG and EEG data files\n",
    "    emg_path = 'data/processed/EMG-data.csv'\n",
    "    eeg_path = 'data/processed/EEG-data.csv'\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    emg_data, eeg_data = load_and_preprocess_data(emg_path, eeg_path)\n",
    "    \n",
    "    # No need to convert again, already done in load_and_preprocess_data\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = EMGEEGDataset(emg_data, eeg_data)\n",
    "    \n",
    "    # Split dataset into train, validation, and test sets\n",
    "    train_size = int(0.7 * len(dataset))\n",
    "    val_size = int(0.15 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        dataset, [train_size, val_size, test_size]\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset splits: Train {train_size}, Validation {val_size}, Test {test_size}\")\n",
    "    \n",
    "    # Create data loaders with memory-efficient batch sizes\n",
    "    batch_size = 16  # Small batch size to save memory\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    # Count number of classes\n",
    "    num_classes = len(np.unique(dataset.labels))\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    \n",
    "    # Create model with correct window size parameter\n",
    "    window_size = 1000  # Same as in the dataset class\n",
    "    model = MultimodalCNN(num_classes=num_classes, window_size=window_size).to(device)\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    \n",
    "    # Train model\n",
    "    model = train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, num_epochs=50, patience=10)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for emg_data, eeg_data, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            emg_data, eeg_data, labels = emg_data.to(device), eeg_data.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(emg_data, eeg_data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_acc = test_correct / test_total\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
